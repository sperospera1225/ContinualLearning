{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c904830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler\n",
    "from pyspark.ml.feature import StopWordsRemover, Word2Vec, RegexTokenizer, Tokenizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import Row\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "import pyspark.sql.functions as f\n",
    "import json\n",
    "import re\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "import sys\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "import pickle\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import zeros\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d68cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea497ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://kafka1:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "258bd0ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://kafka1:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc595590b70>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8e9184a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7fc4ea748b70>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d5398a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_pos_neg = spark.read.csv(\"hdfs:///user/spark/datafile/csiposneg.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf5f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = spark.read.csv(\"hdfs:///user/spark/datafile/fourth_test.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bceac547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "|_c0|                text|label|\n",
      "+---+--------------------+-----+\n",
      "|  0|threatmeter hacke...|    0|\n",
      "|  1|first android mal...|    0|\n",
      "|  2|adobe fixes six c...|    0|\n",
      "|  3| scienceporn  in ...|    0|\n",
      "|  4|riskware hmoyfzb ...|    0|\n",
      "+---+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csi_pos_neg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb62bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+-----+\n",
      "|_c0|Unnamed: 0|                text|label|\n",
      "+---+----------+--------------------+-----+\n",
      "|  0|    332843| osxreverser  ove...|    0|\n",
      "|  1|    292748|hackerfanatic yom...|    0|\n",
      "|  2|   1024662|cve nginx http pr...|    0|\n",
      "|  3|   2645604|jvndboracle mysql...|    0|\n",
      "|  4|   1831637|rt geeknik  monoc...|    0|\n",
      "+---+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ddd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec48f040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|49878|\n",
      "|    1|49878|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ddd.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3ceb625",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-a0accb6dc603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24939\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m49878\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m49878\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m74817\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ddd' is not defined"
     ]
    }
   ],
   "source": [
    "a1 = ddd.collect()[24939:49878]\n",
    "a2 = ddd.collect()[49878:74817]\n",
    "\n",
    "a1 = spark.createDataFrame(a1)\n",
    "a2 = spark.createDataFrame(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68cb87cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-438d2098207d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_c0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a1' is not defined"
     ]
    }
   ],
   "source": [
    "a1 = a1.drop('_c0').drop('Unnamed: 0')\n",
    "a1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "741c9c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|text                                                                                                                                  |label|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|for whom the baja blasts                                                                                                              |1    |\n",
      "|its scary how accurate that thing about girls being upset and then coming online and finding a tweet that describes their situation is|1    |\n",
      "|this is a peaceful rally the sole purpose of the crowd is to demonstrate how angry people are towards the national securi             |1    |\n",
      "|me im so forgiving                                                                                                                    |1    |\n",
      "|loved this one jason great cock                                                                                                       |1    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a2 = a2.drop('_c0').drop('Unnamed: 0')\n",
    "a2.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "244a7487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|operation emmenta...|    0|\n",
      "|credit card numbe...|    0|\n",
      "|tor browser app i...|    0|\n",
      "|people follow lea...|    0|\n",
      "|huawei reports  p...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f4 = a1.union(a2)\n",
    "f4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75d4a725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|24939|\n",
      "|    1|24939|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f4.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "001adcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|operation emmenta...|    0|\n",
      "|credit card numbe...|    0|\n",
      "|tor browser app i...|    0|\n",
      "|people follow lea...|    0|\n",
      "|huawei reports  p...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5784e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "|_c0|                text|label|\n",
      "+---+--------------------+-----+\n",
      "|  0|threatmeter hacke...|    0|\n",
      "|  1|first android mal...|    0|\n",
      "|  2|adobe fixes six c...|    0|\n",
      "|  3| scienceporn  in ...|    0|\n",
      "|  4|riskware hmoyfzb ...|    0|\n",
      "+---+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csi_pos_neg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e54b9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi_pos_neg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d03b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|99756|\n",
      "|    1|99756|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csi_pos_neg.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58521530",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_pos_neg = csi_pos_neg.orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f740ae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|windows xp endofl...|    0|\n",
      "|unite against rac...|    1|\n",
      "|dropbox files pet...|    0|\n",
      "|hdp for retailers...|    0|\n",
      "|meal prep doesnt ...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csi_pos_neg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fafb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_pos_neg = csi_pos_neg.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a73c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = csi_pos_neg.collect()[:24939]\n",
    "t2 = csi_pos_neg.collect()[24939:49878]\n",
    "t3 = csi_pos_neg.collect()[49878:74817]\n",
    "t4 = csi_pos_neg.collect()[74817:99756]\n",
    "\n",
    "t5 = csi_pos_neg.collect()[99756:124695]\n",
    "t6 = csi_pos_neg.collect()[124695:149634]\n",
    "t7 = csi_pos_neg.collect()[149634:174573]\n",
    "t8 = csi_pos_neg.collect()[174573:199512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a346e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = spark.createDataFrame(t1)\n",
    "t2 = spark.createDataFrame(t2)\n",
    "t3 = spark.createDataFrame(t3)\n",
    "t4 = spark.createDataFrame(t4)\n",
    "\n",
    "t5 = spark.createDataFrame(t5)\n",
    "t6 = spark.createDataFrame(t6)\n",
    "t7 = spark.createDataFrame(t7)\n",
    "t8 = spark.createDataFrame(t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8a55122",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tᄋ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-53bfdeaed178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtㅇ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tᄋ' is not defined"
     ]
    }
   ],
   "source": [
    "tㅇ.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3393b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|24939|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t8.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb926aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_train=t1.union(t5) #word_counts_1 t1\n",
    "first_test=t2.union(t6)\n",
    "second_train=first_train.union(first_test) #word_counts_1 t1, t2\n",
    "second_test=t3.union(t7)\n",
    "third_train=second_train.union(second_test)\n",
    "third_test=t4.union(t8)\n",
    "fourth_train=third_train.union(third_test)\n",
    "#fourth_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c7d9be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|threatmeter hacke...|    1|\n",
      "|first android mal...|    1|\n",
      "|adobe fixes six c...|    1|\n",
      "| scienceporn  in ...|    1|\n",
      "|riskware hmoyfzb ...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fourth_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7f22681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199512"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb9e48b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|99756|\n",
      "|    1|99756|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csi_pos_neg.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1796fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_train = fourth_train.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dcd7d90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-50088cbffbcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfourth_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfourth_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f4' is not defined"
     ]
    }
   ],
   "source": [
    "fourth_test = fourth_train.union(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51af9666",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fourth_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bd9d2d43fd3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfourth_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fourth_test' is not defined"
     ]
    }
   ],
   "source": [
    "fourth_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe52301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_test = second_train.union(second_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1b13c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_test = third_train.union(third_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f206a88f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|24939|\n",
      "|    1|24939|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_train.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b58295ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|24939|\n",
      "|    0|24939|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_test.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ab4d041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|49878|\n",
      "|    1|49878|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "second_train.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2eb7cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|74817|\n",
      "|    1|74817|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "second_test.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90682e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149634"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1248d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|74817|\n",
      "|    1|74817|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "third_train.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "88c34a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|99756|\n",
      "|    1|99756|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "third_test.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "09b1ea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|99756|\n",
      "|    1|99756|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fourth_train.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "72b27934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    0|149634|\n",
      "|    1|149634|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fourth_test.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39dd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = csi_pos_neg.collect()[:49878]\n",
    "# df2 = csi_pos_neg.collect()[49878:99756]\n",
    "# df3 = csi_pos_neg.collect()[99756:149634]\n",
    "# df4 = csi_pos_neg.collect()[149634:199512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37ded1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = spark.createDataFrame(df1)\n",
    "# df2 = spark.createDataFrame(df2)\n",
    "# df3 = spark.createDataFrame(df3)\n",
    "# df4 = spark.createDataFrame(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9beb6374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi_pos_neg.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17aea5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csi_pos_neg = csi_pos_neg.repartition(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bcc26ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csi_pos_neg.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/word_counts1.json') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "word_counts_1 = {}\n",
    "for i in json_data:\n",
    "    word_counts_1.update({i[0]:i[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4567d0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.broadcast.Broadcast at 0x7fc4f2653a90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc118a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_1 = sc.broadcast(word_counts_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50690b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/word_counts2.json') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "word_counts_2 = {}\n",
    "for i in json_data:\n",
    "    word_counts_2.update({i[0]:i[1]})\n",
    "word_counts_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4683d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_2 = sc.broadcast(word_counts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1da1f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.programmerall.com/article/89051746485/ -> broadcast 변수 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714297a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_tokens 함수과 같은 용도\n",
    "stage_1 = RegexTokenizer(inputCol= 'text', outputCol='pos_t', pattern= '\\\\W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26428fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r1 = stage_1.transform(first_train)\n",
    "r1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_lemma 함수와 같은 용도\n",
    "stage_2 = StopWordsRemover(inputCol= stage_1.getOutputCol(), outputCol= 'filtered_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e62d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = stage_2.transform(r1)\n",
    "r2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa514f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49878"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "868383b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcastWrapper(object):\n",
    "    def __init__(self, data, token_list):\n",
    "        self.broadcast_var = data\n",
    "#         self.last_updated_time = datetime.now()\n",
    "        self.token_list = token_list\n",
    "    \n",
    "#     def is_should_be_updated(self, data):\n",
    "#         cur_time = datetime.now()\n",
    "#         diff_sec = (cur_time - self.last_updated_time).total_seconds()\n",
    "#         return self.broadcast_var is None or diff_sec> 1\n",
    "    \n",
    "    def update_and_get_data(self, spark):\n",
    "        a = self.broadcast_var.value\n",
    "        self.broadcast_var.unpersist()\n",
    "        for i in self.token_list:\n",
    "            a[i] += 1\n",
    "        new_data = a\n",
    "        self.broadcast_var = spark.broadcast(new_data)\n",
    "#         self.last_updated_time = datetime.now()\n",
    "#         return len(self.token_list)\n",
    "        return self.broadcast_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "048642a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlkt_analysis(text):\n",
    "    broadcast_wrapper = BroadcastWrapper(word_counts_1, text)\n",
    "    length = broadcast_wrapper.update_and_get_data(sc)\n",
    "    return length\n",
    "    return new_data.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59297599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/spark/python/pyspark/serializers.py\", line 597, in dumps\n",
      "    return cloudpickle.dumps(obj, 2)\n",
      "  File \"/root/spark/python/pyspark/cloudpickle.py\", line 863, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/root/spark/python/pyspark/cloudpickle.py\", line 260, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 409, in dump\n",
      "    self.save(obj)\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 736, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/root/spark/python/pyspark/cloudpickle.py\", line 400, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/root/spark/python/pyspark/cloudpickle.py\", line 549, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 821, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 821, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/lib/python3.6/pickle.py\", line 496, in save\n",
      "    rv = reduce(self.proto)\n",
      "  File \"/root/spark/python/pyspark/context.py\", line 339, in __getnewargs__\n",
      "    \"It appears that you are attempting to reference SparkContext from a broadcast \"\n",
      "Exception: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: Exception: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/spark/python/pyspark/serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0;31m# Subtle.  Same as in the big comment below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 or themodule is None):\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'qualname'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__getnewargs__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m         raise Exception(\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0;34m\"It appears that you are attempting to reference SparkContext from a broadcast \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0;34m\"variable, action, or transformation. SparkContext can only be used on the driver, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a1698f97a234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mudf_nlkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlkt_analysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf_nlkt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filtered_words\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massignments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mjudf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36m_judf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# and should have a minimal performance impact.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_judf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36m_create_judf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mjdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseDataType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         judf = sc._jvm.org.apache.spark.sql.execution.python.UserDefinedPythonFunction(\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, returnType)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[1;32m     37\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n",
      "\u001b[0;32m~/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;31m# the serialized command will be compressed by broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0mpickled_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 1M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not serialize object: %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not serialize object: Exception: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063."
     ]
    }
   ],
   "source": [
    "udf_nlkt = udf(nlkt_analysis, StringType())    \n",
    "new_df = r2.withColumn(\"temp\", udf_nlkt(\"filtered_words\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe61847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c95d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37193833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "stage_3 = CountVectorizer(inputCol=stage_2.getOutputCol(), outputCol='word1', vocabSize=50, minDF=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da9a5793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+---------------+\n",
      "|                text|label|               pos_t|      filtered_words|          word1|\n",
      "+--------------------+-----+--------------------+--------------------+---------------+\n",
      "|threatmeter hacke...|    1|[threatmeter, hac...|[threatmeter, hac...| (50,[4],[1.0])|\n",
      "|first android mal...|    1|[first, android, ...|[first, android, ...|(50,[35],[1.0])|\n",
      "|adobe fixes six c...|    1|[adobe, fixes, si...|[adobe, fixes, si...|     (50,[],[])|\n",
      "| scienceporn  in ...|    1|[scienceporn, in,...|[scienceporn, vac...|     (50,[],[])|\n",
      "|riskware hmoyfzb ...|    1|[riskware, hmoyfz...|[riskware, hmoyfz...|     (50,[],[])|\n",
      "+--------------------+-----+--------------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r3 = stage_3.fit(r2).transform(r2)\n",
    "r3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7850cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- pos_t: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- word1: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75934820",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e21e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf01541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0b639dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      filtered_words|\n",
      "+--------------------+\n",
      "|[threatmeter, hac...|\n",
      "|[first, android, ...|\n",
      "|[adobe, fixes, si...|\n",
      "|[scienceporn, vac...|\n",
      "|[riskware, hmoyfz...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = r2.select(\"filtered_words\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ecc39d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_t = Tokenizer()\n",
    "neg_t = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07281e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vocab = [w for i, w in enumerate(word_counts_1) if i < 5000]\n",
    "neg_vocab = [w for i, w in enumerate(word_counts_2) if i < 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "432e02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_t.fit_on_texts(pos_vocab)\n",
    "neg_t.fit_on_texts(neg_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9952000",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs_pos = pos_t.texts_to_sequences(df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c559bad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filtered_words'], dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "670a016e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[threatmeter, hacked, emails, san, francisco, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[first, android, malware, targeting, pcs, unco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[adobe, fixes, six, code, execution, bugs, fla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[scienceporn, vacuum, guess]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[riskware, hmoyfzb, fbjaz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49873</th>\n",
       "      <td>[hi, lil, monster, lives, super, ridecheers, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49874</th>\n",
       "      <td>[topleftbrick, veronica, mikeyil, totally, fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49875</th>\n",
       "      <td>[lovely, day, golf, bob, schulz, scott, pemric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49876</th>\n",
       "      <td>[manufacturing, job, might, great, fit, click,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49877</th>\n",
       "      <td>[culture, welcomes, ideas, amp, opportunities,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49878 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          filtered_words\n",
       "0      [threatmeter, hacked, emails, san, francisco, ...\n",
       "1      [first, android, malware, targeting, pcs, unco...\n",
       "2      [adobe, fixes, six, code, execution, bugs, fla...\n",
       "3                           [scienceporn, vacuum, guess]\n",
       "4                             [riskware, hmoyfzb, fbjaz]\n",
       "...                                                  ...\n",
       "49873  [hi, lil, monster, lives, super, ridecheers, i...\n",
       "49874  [topleftbrick, veronica, mikeyil, totally, fai...\n",
       "49875  [lovely, day, golf, bob, schulz, scott, pemric...\n",
       "49876  [manufacturing, job, might, great, fit, click,...\n",
       "49877  [culture, welcomes, ideas, amp, opportunities,...\n",
       "\n",
       "[49878 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7949710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a16bb35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105727"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_1.value['allow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c46bdc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'allow' not in word_counts_1.value.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0653480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcastWrapper(object):\n",
    "    def __init__(self, data, token_list):\n",
    "        self.broadcast_var = sc.broadcast(data)\n",
    "#         self.last_updated_time = datetime.now()\n",
    "        self.token_list = token_list\n",
    "    \n",
    "#     def is_should_be_updated(self, data):\n",
    "#         cur_time = datetime.now()\n",
    "#         diff_sec = (cur_time - self.last_updated_time).total_seconds()\n",
    "#         return self.broadcast_var is None or diff_sec> 1\n",
    "    \n",
    "    def update_and_get_data(self, spark):\n",
    "        a = self.broadcast_var.value\n",
    "        self.broadcast_var.unpersist()\n",
    "        for i in self.token_list:\n",
    "            for j in i:\n",
    "                if j not in a.keys():\n",
    "                    a[j] = 1\n",
    "                else:\n",
    "                    a[j] += 1\n",
    "        new_data = a\n",
    "        self.broadcast_var = spark.broadcast(new_data)\n",
    "#         self.last_updated_time = datetime.now()\n",
    "#         return len(self.token_list)\n",
    "        return self.broadcast_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5438a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dynamic word ranking 고려x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fac6f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "class TextToSequence(Transformer):\n",
    "    \n",
    "    pos_t = Tokenizer()\n",
    "    neg_t = Tokenizer()\n",
    "    pos_vocab = []\n",
    "    neg_vocab = []\n",
    "    \n",
    "    def __init__(self, w1: Dict[str, int], w2:Dict[str, int]):\n",
    "        super(TextToSequence, self).__init__()\n",
    "\n",
    "        self.pos_vocab = [w for i, w in enumerate(w1) if i < 5000]\n",
    "        self.neg_vocab = [w for i, w in enumerate(w2) if i < 5000]\n",
    "    \n",
    "    \n",
    "    def _transform(self, df: DataFrame):\n",
    "        df = df.toPandas()\n",
    "        X = []\n",
    "        self.pos_t.fit_on_texts(self.pos_vocab)\n",
    "        self.neg_t.fit_on_texts(self.neg_vocab)\n",
    "        print(self.pos_vocab)\n",
    "#         encoded_docs_pos = self.pos_t.texts_to_sequences(df.select(\"filtered_words1\").toPandas())\n",
    "#         encoded_docs_neg = self.neg_t.texts_to_sequences(df.select(\"filtered_words1\").toPandas())\n",
    "        encoded_docs_pos = self.pos_t.texts_to_sequences(df[\"filtered_words\"])\n",
    "        encoded_docs_neg = self.neg_t.texts_to_sequences(df[\"filtered_words\"])\n",
    "\n",
    "        X_p = pad_sequences(encoded_docs_pos, maxlen=100, padding='post')\n",
    "        X_n = pad_sequences(encoded_docs_neg, maxlen=100, padding='post')\n",
    "\n",
    "        df = df.assign(feature1 = X_p.tolist())\n",
    "        df = df.assign(feature2 = X_n.tolist())\n",
    "        \n",
    "#         cols = ['feature1','feature2']\n",
    "#         def feature_add(x) :\n",
    "#             tmp = []\n",
    "#             tmp.append(x.values)\n",
    "#             return tmp[0].tolist()\n",
    "        \n",
    "#         df.insert(0, 'features', df[cols].apply(feature_add, axis=1))\n",
    "        \n",
    "        fdf = spark.createDataFrame(df)\n",
    "        return fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynmaic word ranking 고려o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de1e44",
   "metadata": {},
   "source": [
    "# Train용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1978148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249390"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69d5bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "class TextToSequence(Transformer):\n",
    "    w1 = dict()\n",
    "    w2 = dict()\n",
    "    pos_t = Tokenizer()\n",
    "    neg_t = Tokenizer()\n",
    "    pos_vocab = []\n",
    "    neg_vocab = []\n",
    "    \n",
    "    def __init__(self, w1: Dict[str, int], w2:Dict[str, int]):\n",
    "        super(TextToSequence, self).__init__()\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        \n",
    "    \n",
    "    def _transform(self, df: DataFrame):\n",
    "        df = df.toPandas()\n",
    "        pos_df = df[:99756]\n",
    "        neg_df = df[99756:]\n",
    "        \n",
    "        broadcast_wrapper1 = BroadcastWrapper(self.w1, pos_df[\"filtered_words\"])\n",
    "        ww1 = broadcast_wrapper1.update_and_get_data(sc).value\n",
    "        \n",
    "        broadcast_wrapper2 = BroadcastWrapper(self.w2, neg_df[\"filtered_words\"])\n",
    "        ww2 = broadcast_wrapper2.update_and_get_data(sc).value\n",
    "        \n",
    "        www1 = {k: v for k, v in sorted(ww1.items(), key=lambda item: item[1], reverse=True)}\n",
    "        www2 = {k: v for k, v in sorted(ww2.items(), key=lambda item: item[1], reverse=True)}\n",
    "        \n",
    "        aa = [w for i, w in enumerate(www1) if i < 5000]\n",
    "        bb = [w for i, w in enumerate(www2) if i < 5000]\n",
    "        \n",
    "        self.pos_t.fit_on_texts(aa)\n",
    "        self.neg_t.fit_on_texts(bb)\n",
    "        print(aa)\n",
    "#         encoded_docs_pos = self.pos_t.texts_to_sequences(df.select(\"filtered_words1\").toPandas())\n",
    "#         encoded_docs_neg = self.neg_t.texts_to_sequences(df.select(\"filtered_words1\").toPandas())\n",
    "        encoded_docs_pos = self.pos_t.texts_to_sequences(df[\"filtered_words\"])\n",
    "        encoded_docs_neg = self.neg_t.texts_to_sequences(df[\"filtered_words\"])\n",
    "        print(encoded_docs_pos[:10])\n",
    "        X_p = pad_sequences(encoded_docs_pos, maxlen=100, padding='post')\n",
    "        X_n = pad_sequences(encoded_docs_neg, maxlen=100, padding='post')\n",
    "\n",
    "        df = df.assign(feature1 = X_p.tolist())\n",
    "        df = df.assign(feature2 = X_n.tolist())\n",
    "        \n",
    "#         cols = ['feature1','feature2']\n",
    "#         def feature_add(x) :\n",
    "#             tmp = []\n",
    "#             tmp.append(x.values)\n",
    "#             return tmp[0].tolist()\n",
    "        \n",
    "#         df.insert(0, 'features', df[cols].apply(feature_add, axis=1))\n",
    "        \n",
    "        fdf = spark.createDataFrame(df)\n",
    "        return fdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7fc58",
   "metadata": {},
   "source": [
    "# TEST용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c001678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "class TextToSequence(Transformer):\n",
    "    w1 = dict()\n",
    "    w2 = dict()\n",
    "    pos_t = Tokenizer()\n",
    "    neg_t = Tokenizer()\n",
    "    pos_vocab = []\n",
    "    neg_vocab = []\n",
    "    \n",
    "    def __init__(self, w1: Dict[str, int], w2:Dict[str, int]):\n",
    "        super(TextToSequence, self).__init__()\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        \n",
    "    \n",
    "    def _transform(self, df: DataFrame):\n",
    "        df = df.toPandas()\n",
    "        cut_df = df[:199512]\n",
    "        df = df[199512:]\n",
    "        # csi_pos인 filtered_words에 대해서만...\n",
    "        broadcast_wrapper1 = BroadcastWrapper(self.w1, cut_df[\"filtered_words\"][:99756])\n",
    "        ww1 = broadcast_wrapper1.update_and_get_data(sc).value\n",
    "        \n",
    "        broadcast_wrapper2 = BroadcastWrapper(self.w2, cut_df[\"filtered_words\"][99756:])\n",
    "        ww2 = broadcast_wrapper2.update_and_get_data(sc).value\n",
    "        \n",
    "        www1 = {k: v for k, v in sorted(ww1.items(), key=lambda item: item[1], reverse=True)}\n",
    "        www2 = {k: v for k, v in sorted(ww2.items(), key=lambda item: item[1], reverse=True)}\n",
    "        \n",
    "        aa = [w for i, w in enumerate(www1) if i < 5000]\n",
    "        bb = [w for i, w in enumerate(www2) if i < 5000]\n",
    "        \n",
    "        self.pos_t.fit_on_texts(aa)\n",
    "        self.neg_t.fit_on_texts(bb)\n",
    "        print(aa)\n",
    "#         encoded_docs_pos = self.pos_t.texts_to_sequences(df.select(\"filtered_words1\").toPandas())\n",
    "#         encoded_docs_neg = self.neg_t.texts_to_sequences(df.select(\"filtered_words1\").toPandas())\n",
    "        encoded_docs_pos = self.pos_t.texts_to_sequences(df[\"filtered_words\"])\n",
    "        encoded_docs_neg = self.neg_t.texts_to_sequences(df[\"filtered_words\"])\n",
    "        print(encoded_docs_pos[:10])\n",
    "        X_p = pad_sequences(encoded_docs_pos, maxlen=100, padding='post')\n",
    "        X_n = pad_sequences(encoded_docs_neg, maxlen=100, padding='post')\n",
    "\n",
    "        df = df.assign(feature1 = X_p.tolist())\n",
    "        df = df.assign(feature2 = X_n.tolist())\n",
    "        \n",
    "#         cols = ['feature1','feature2']\n",
    "#         def feature_add(x) :\n",
    "#             tmp = []\n",
    "#             tmp.append(x.values)\n",
    "#             return tmp[0].tolist()\n",
    "        \n",
    "#         df.insert(0, 'features', df[cols].apply(feature_add, axis=1))\n",
    "        \n",
    "        fdf = spark.createDataFrame(df)\n",
    "        return fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "731f41da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+\n",
      "|filtered_words                                                   |\n",
      "+-----------------------------------------------------------------+\n",
      "|[blacklivesmatter, blm, ldn, blmldn, ldnblm, us, embassy, london]|\n",
      "+-----------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r2.select(\"filtered_words\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eacb5d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [want, land, job, like, sales, representative,...\n",
       "1        [fitness, friends, like, gold, rare, valuable,...\n",
       "2        [tradecalls, nomura, maintains, palo, alto, ne...\n",
       "3        [job, might, great, fit, rn, staff, skilled, n...\n",
       "4                   [im, seafood, junction, oak, park, il]\n",
       "                               ...                        \n",
       "49873    [heres, challenge, teacher, friends, students,...\n",
       "49874    [greatest, shot, tallest, hill, behind, ive, a...\n",
       "49875    [nothing, musical, sunset, claude, debussy, ca...\n",
       "49876    [ipv, focus, month, warm, fuzzy, side, ipv, tu...\n",
       "49877    [big, data, minute, making, sense, new, natura...\n",
       "Name: filtered_words, Length: 49878, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdfasdf = r2.toPandas()\n",
    "asdfasdf[\"filtered_words\"][:-49878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a3867222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [want, land, job, like, sales, representative,...\n",
       "1        [fitness, friends, like, gold, rare, valuable,...\n",
       "2        [tradecalls, nomura, maintains, palo, alto, ne...\n",
       "3        [job, might, great, fit, rn, staff, skilled, n...\n",
       "4                   [im, seafood, junction, oak, park, il]\n",
       "                               ...                        \n",
       "99751    [disorderly, conduct, charge, handing, cardboa...\n",
       "99752    [techcentral, third, data, protection, pros, a...\n",
       "99753    [good, morning, montevideo, sunrise, noon, sun...\n",
       "99754    [euleros, sp, dockerengine, eulerossa, tenable...\n",
       "99755    [pret, chicken, caesar, amp, bacon, baguette, ...\n",
       "Name: filtered_words, Length: 99756, dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdfasdf[\"filtered_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88d30caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allow', 'attacker', 'via', 'vulnerability', 'remote', 'arbitrary', 'cve', 'user', 'execute', 'file', 'code', 'service', 'script', 'cause', 'parameter', 'server', 'denial', 'craft', 'version', 'web', 'access', 'earlier', 'unspecified', 'vector', 'information', 'windows', 'affect', 'x', 'sql', 'aka', 'privilege', 'local', 'attack', 'command', 'oracle', 'data', 'could', 'application', 'crosssite', 'memory', 'function', 'overflow', 'security', 'issue', 'use', 'request', 'buffer', 'html', 'obtain', 'inject', 'multiple', 'system', 'crash', 'injection', 'id', 'authenticate', 'sp', 'component', 'android', 'read', 'relate', 'sensitive', 'microsoft', 'sd', 'impact', 'possibly', 'prior', 'directory', 'properly', 'unknown', 'exploit', 'php', 'network', 'execution', 'bypass', 'product', 'http', 'cisco', 'ibm', 'result', 'different', 'note', 'corruption', 'may', 'url', 'job', 'cybersecurity', 'successful', 'password', 'kernel', 'gain', 'exist', 'device', 'linux', 'discover', 'os', 'software', 'certain', 'management', 'authentication', 'vrc', 'new', 'manager', 'using', 'control', 'page', 'adobe', 'cv', 'java', 'message', 'malicious', 'trigger', 'module', 'certificate', 'contain', 'lead', 'apple', 'unauthorized', 'packet', 'long', 'due', 'site', 'devices', 'process', 'link', 'traversal', 'enterprise', 'update', 'internet', 'support', 'check', 'interface', 'like', 'bug', 'object', 'action', 'dot', 'plugin', 'name', 'disclosure', 'vulnerable', 'hacker', 'unauthenticated', 'demonstrate', 'integrity', 'confidentiality', 'client', 'base', 'open', 'handle', 'exploitable', 'error', 'might', 'store', 'enable', 'address', 'firmware', 'snapdragon', 'input', 'path', 'modify', 'click', 'value', 'firefox', 'score', 'configuration', 'google', 'permission', 'compromise', 'call', 'make', 'io', 'wordpress', 'include', 'spoof', 'administrator', 'accessible', 'require', 'root', 'indexphp', 'details', 'field', 'driver', 'create', 'integer', 'write', 'reader', 'see', 'session', 'image', 'free', 'acrobat', 'account', 'services', 'explorer', 'upload', 'bio', 'string', 'within', 'javascript', 'se', 'us', 'availability', 'header', 'time', 'implementation', 'database', 'rt', 'engine', 'one', 'potentially', 'series', 'need', 'apply', 'csrf', 'validation', 'mac', 'day', 'delete', 'interaction', 'build', 'credentials', 'email', 'release', 'chrome', 'ssl', 'exploitation', 'content', 'mobile', 'pointer', 'key', 'conduct', 'heapbased', 'get', 'maninthemiddle', 'mysql', 'fix', 'party', 'app', 'intend', 'involve', 'port', 'im', 'search', 'third', 'library', 'change', 'suite', 'log', 'mdm', 'context', 'latest', 'office', 'argument', 'outofbounds', 'verify', 'stackbased', 'set', 'easily', 'document', 'null', 'feature', 'today', 'perform', 'extension', 'protocol', 'view', 'restriction', 'dos', 'large', 'running', 'without', 'protection', 'method', 'functionality', 'player', 'type', 'default', 'photo', 'inclusion', 'invalid', 'forgery', 'gold', 'hacking', 'condition', 'easy', 'program', 'xml', 'possible', 'malformed', 'validate', 'list', 'additional', 'work', 'great', 'host', 'variable', 'api', 'subcomponent', 'sending', 'platform', 'leveraging', 'character', 'hiring', 'posted', 'consumption', 'specially', 'sdm', 'leading', 'improper', 'dereference', 'elevation', 'first', 'format', 'connection', 'malware', 'send', 'air', 'sun', 'edition', 'incorrect', 'cm', 'direct', 'setting', 'current', 'way', 'resource', 'apache', 'flaw', 'securityaffairs', 'amp', 'number', 'center', 'overwrite', 'admin', 'useafterfree', 'insufficient', 'browser', 'installation', 'response', 'embed', 'handling', 'cookie', 'know', 'msm', 'target', 'ip', 'bitcoin', 'login', 'sequence', 'mozilla', 'leak', 'flash', 'post', 'shell', 'specific', 'found', 'username', 'restrict', 'want', 'hijack', 'patch', 'dont', 'well', 'critical', 'th', 'insert', 'download', 'follow', 'outside', 'lack', 'uri', 'complete', 'run', 'business', 'xforce', 'daemon', 'cyber', 'tcp', 'processing', 'unique', 'framework', 'peoplesoft', 'values', 'appliance', 'sunday', 'administrative', 'report', 'domain', 'escalation', 'length', 'operations', 'jobs', 'package', 'mode', 'guest', 'technology', 'source', 'reading', 'webkit', 'infosec', 'video', 'occur', 'token', 'r', 'secure', 'looking', 'untrusted', 'pm', 'another', 'environment', 'high', 'cpu', 'provide', 'news', 'solaris', 'size', 'redirect', 'connect', 'core', 'filter', 'add', 'group', 'tool', 'internal', 'opening', 'policy', 'filename', 'router', 'hp', 'query', 'form', 'option', 'reference', 'love', 'virtual', 'configure', 'full', 'heap', 'leverage', 'medium', 'bounds', 'sdk', 'controller', 'pro', 'sales', 'stack', 'ca', 'parse', 'youre', 'cloud', 'traffic', 'c', 'trust', 'human', 'must', 'smart', 'safari', 'portal', 'able', 'rc', 'line', 'black', 'back', 'quote', 'home', 'thunderbird', 'ability', 'iot', 'beta', 'vrcspc', 'ftp', 'edge', 'also', 'mishandle', 'mechanism', 'state', 'go', 'people', 'hang', 'team', 'person', 'good', 'jenkins', 'switch', 'external', 'ui', 'vm', 'drupal', 'miss', 'joomla', 'pdf', 'project', 'city', 'sap', 'attribute', 'tag', 'console', 'display', 'level', 'red', 'associate', 'improperly', 'online', 'entity', 'low', 'phone', 'world', 'qualcomm', 'loop', 'fail', 'activex', 'location', 'even', 'symlink', 'point', 'part', 'victim', 'userassisted', 'private', 'text', 'event', 'operate', 'class', 'would', 'provenance', 'alert', 'm', 'cross', 'antivirus', 'fit', 'dns', 'place', 'significantly', 'contract', 'gateway', 'valid', 'happy', 'join', 'cf', 'dc', 'esr', 'advance', 'pass', 'xp', 'db', 'infrastructure', 'element', 'excel', 'temporary', 'fields', 'available', 'contextdependent', 'hackers', 'community', 'mail', 'samsung', 'macos', 'share', 'bit', 'hat', 'race', 'specify', 'virtualbox', 'identify', 'anyone', 'agent', 'property', 'start', 'attempt', 'xd', 'wireless', 'block', 'word', 'table', 'park', 'endpoint', 'trojan', 'retail', 'end', 'many', 'solely', 'overread', 'n', 'binary', 'nexus', 'best', 'array', 'storage', 'look', 'comment', 'vmware', 'take', 'co', 'cache', 'order', 'fusion', 'last', 'infinite', 'vista', 'node', 'failure', 'visit', 'load', 'return', 'life', 'case', 'wind', 'receive', 'sent', 'hospitality', 'parser', 'symantec', 'live', 'week', 'prevent', 'banking', 'incident', 'reflect', 'encryption', 'firewall', 'help', 'dll', 'xx', 'reports', 'phishing', 'later', 'metacharacters', 'desktop', 'website', 'insecure', 'names', 'still', 'machine', 'ebusiness', 'public', 'two', 'operation', 'right', 'stop', 'every', 'partial', 'protect', 'webbased', 'authorization', 'station', 'subset', 'generate', 'role', 'recommend', 'record', 'clear', 'horse', 'pack', 'handler', 'digital', 'unify', 'rain', 'cleartext', 'apps', 'websphere', 'entry', 'itunes', 'reload', 'net', 'big', 'backup', 'next', 'middleware', 'proxy', 'vulnerabilities', 'intelligence', 'signature', 'st', 'disabled', 'contents', 'huawei', 'threatmeter', 'structure', 'book', 'sm', 'fp', 'runtime', 'tvos', 'wifi', 'simple', 'frame', 'administration', 'title', 'camera', 'hash', 'v', 'identity', 'master', 'zdican', 'financial', 'force', 'beautiful', 'appear', 'ransomware', 'na', 'breach', 'executable', 'emc', 'little', 'peopletools', 'archive', 'weak', 'profile', 'music', 'panel', 'folder', 'blog', 'exit', 'reset', 'york', 'ipv', 'attacks', 'seamonkey', 'thus', 'working', 'filesystem', 'morning', 'font', 'universal', 'w', 'kmh', 'usersupplied', 'ssh', 'thanks', 'exploits', 'simatic', 'sharepoint', 'byte', 'computer', 'ioctl', 'show', 'foodwaste', 'subsystem', 'incomplete', 'june', 'come', 'fl', 'rate', 'tibco', 'viewer', 'career', 'iphone', 'family', 'blacklivesmatter', 'space', 'eg', 'install', 'wireshark', 'determine', 'starting', 'register', 'threat', 'reveal', 'small', 'ifix', 'facebook', 'expose', 'caf', 'foxit', 'creation', 'classic', 'global', 'analysis', 'f', 'formerly', 'vuln', 'pathname', 'consumer', 'lock', 'health', 'including', 'california', 'beach', 'ever', 'sessions', 'forum', 'top', 'advisory', 'guide', 'unitedkingdom', 'weblogic', 'graphics', 'description', 'imagemagick', 'exchange', 'active', 'systems', 'social', 'improve', 'common', 'sdx', 'foundation', 'applesa', 'deployment', 'things', 'index', 'communications', 'screen', 'auto', 'users', 'power', 'test', 'xxe', 'tonight', 'flexcube', 'solution', 'intel', 'birthday', 'gnu', 'mp', 'drinking', 'rsa', 'lake', 'hpe', 'stream', 'trick', 'jre', 'payload', 'escape', 'express', 'year', 'years', 'double', 'since', 'making', 'match', 'north', 'customer', 'capability', 'humidity', 'proper', 'ethereum', 'hardcoded', 'gallery', 'micro', 'rational', 'sandbox', 'kit', 'always', 'hi', 'got', 'encrypt', 'weather', 'hack', 'industrial', 'house', 'analytics', 'attachment', 'whether', 'potential', 'standard', 'restart', 'python', 'bar', 'special', 'implement', 'owner', 'submit', 'apq', 'juno', 'disclose', 'man', 'hear', 'interested', 'juniper', 'instal', 'going', 'origin', 'reboot', 'never', 'find', 'modification', 'de', 'causing', 'template', 'ar', 'thank', 'sip', 'tivoli', 'watchos', 'much', 'communication', 'supply', 'ldap', 'expression', 'vpn', 'ms', 'initialize', 'edit', 'disk', 'zero', 'detection', 'cli', 'copy', 'old', 'titles', 'turn', 'typo', 'probably', 'directly', 'e', 'made', 'hf', 'automation', 'custom', 'texas', 'udp', 'dissector', 'design', 'privacy', 'snmp', 'sanitize', 'real', 'contact', 'ny', 'professional', 'tx', 'vendor', 'performing', 'intelligent', 'jun', 'compiler', 'language', 'model', 'sign', 'cybercrime', 'difficult', 'studio', 'instead', 'allocate', 'usb', 'mph', 'uninitialized', 'south', 'conjunction', 'manage', 'openings', 'novell', 'altering', 'utility', 'mcafee', 'already', 'applet', 'side', 'unrestricted', 'audio', 'plus', 'london', 'asa', 'instance', 'connectivity', 'zip', 'inside', 'style', 'healthcare', 'allows', 'consequently', 'allocation', 'physical', 'trend', 'bigip', 'card', 'qcs', 'times', 'oh', 'tl', 'webex', 'frequently', 'logging', 'mm', 'sda', 'personal', 'updated', 'dlink', 'md', 'rd', 'sandboxed', 'pc', 'white', 'development', 'risk', 'keep', 'remove', 'voice', 'police', 'balance', 'meeting', 'en', 'sec', 'secret', 'channel', 'sound', 'strings', 'let', 'everyone', 'says', 'layer', 'tech', 'repeatable', 'window', 'cgi', 'elements', 'united', 'fault', 'previous', 'hacked', 'section', 'logon', 'workstation', 'inc', 'say', 'physically', 'debug', 'rest', 'cant', 'tracking', 'better', 'encode', 'export', 'qemu', 'rule', 'monitor', 'hostname', 'forecast', 'save', 'problem', 'exception', 'variant', 'ubuntu', 'xe', 'icloud', 'knowledge', 'socket', 'route', 'around', 'leadership', 'magento', 'medical', 'b', 'ruby', 'launch', 'second', 'editor', 'board', 'crm', 'limit', 'links', 'really', 'descriptor', 'lo', 'los', 'drive', 'night', 'proximate', 'please', 'nj', 'following', 'accept', 'compute', 'think', 'tools', 'history', 'cs', 'preinstalled', 'days', 'scripting', 'waltitude', 'ftcourse', 'present', 'area', 'unix', 'status', 'xen', 'statement', 'generation', 'pressure', 'executing', 'cr', 'engineering', 'verification', 'regular', 'used', 'installer', 'deletion', 'netgear', 'basic', 'weekend', 'outage', 'container', 'original', 'supplychain', 'exposure', 'claim', 'developer', 'bluetooth', 'monday', 'moodle', 'panic', 'loading', 'example', 'single', 'segmentation', 'safe', 'split', 'openssl', 'currently', 'care', 'gitlab', 'opera', 'plaintext', 'denialofservice', 'gt', 'ios', 'sniff', 'cpanel', 'flag', 'light', 'mb', 'company', 'subject', 'cluster', 'incorrectly', 'capture', 'o', 'calendar', 'chain', 'steal', 'qrd', 'past', 'watch', 'registerglobals', 'however', 'drop', 'underlie', 'upgrade', 'hard', 'existence', 'bank', 'million', 'realplayer', 'la', 'retrieve', 'rely', 'smb', 'ready', 'mn', 'androidversions', 'ga', 'san', 'enforce', 'd', 'adaptive', 'publisher', 'te', 'collaboration', 'body', 'g', 'dark', 'identifier', 'msmw', 'groundspeed', 'zone', 'summer', 'church', 'quicktime', 'asset', 'marketing', 'quick', 'try', 'freebsd', 'friends', 'static', 'nvidia', 'calling', 'fun', 'elevated', 'game', 'minttoken', 'delivery', 'rpc', 'conditions', 'confusion', 'ive', 'transfer', 'disable', 'box', 'distribute', 'nessus', 'xss', 'empty', 'testing', 'getting', 'p', 'eos', 'circumstances', 'ex', 'upon', 'researcher', 'war', 'washington', 'anonymous', 'reporting', 'suse', 'continuous', 'rev', 'processor', 'sunny', 'doesnt', 'fire', 'androidandroid', 'amount', 'nc', 'opportunity', 'telnet', 'repository', 'negative', 'sr', 'general', 'assertion', 'cat', 'coming', 'cdt', 'corrupt', 'escalate', 'wink', 'backend', 'depend', 'walk', 'county', 'protest', 'magicquotesgpc', 'wear', 'market', 'warning', 'vulnerabilityd', 'etailsqidcve', 'virtualization', 'various', 'mi', 'give', 'uk', 'central', 'bad', 'future', 'sve', 'mount', 'several', 'twitter', 'theme', 'art', 'government', 'jpeg', 'usernames', 'takeover', 'random', 'florida', 'algorithm', 'member', 'inch', 'secmash', 'lives', 'lowes', 'aix', 'output', 'printer', 'manipulate', 'hide', 'electric', 'land', 'unprivileged', 'amazing', 'article', 'srx', 'ffmpeg', 'remotely', 'lets', 'specifier', 'exhaustion', 'encoding', 'performance', 'attackers', 'absolute', 'outlook', 'k', 'outbound', 'hijacking', 'decrypt', 'similar', 'limited', 'notification', 'bind', 'print', 'experience', 'nice', 'success', 'lotus', 'consider', 'range', 'national', 'searchphp', 'thats', 'establish', 'discovery', 'persistent', 'become', 'km', 'discovered', 'ticket', 'select', 'thirdparty', 'ft', 'pathinfo', 'integrate', 'dell', 'west', 'mesonet', 'crlf', 'activity', 'sharing', 'everything', 'msmau', 'siebel', 'dhcp', 'nt', 'va', 'imc', 'payment', 'websites', 'intelr', 'import', 'ad', 'plat', 'daily', 'mitm', 'expect', 'school', 'road', 'cleared', 'ethernet', 'director', 'qca', 'wild', 'clock', 'extract', 'chat', 'put', 'transportation', 'learn', 'setuid', 'terminal', 'listing', 'hardware', 'shop', 'food', 'firepower', 'heavy', 'street', 'media', 'cc', 'info', 'hit', 'servlet', 'registry', 'play', 'json', 'sxr', 'cryptographic', 'fabric', 'prime', 'forward', 'provider', 'bridge', 'sc', 'nd', 'close', 'debian', 'websecurity', 'nursing', 'phpmyadmin', 'al', 'matter', 'bugbounty', 'jboss', 'task', 'com', 'queue', 'tiff', 'le', 'something', 'jersey', 'cover', 'rp', 'dir', 'lts', 'defense', 'construction', 'map', 'boot', 'gui', 'nxos', 'integration', 'setup', 'review', 'ne', 'tomcat', 'ensure', 'svg', 'collection', 'blue', 'east', 'assign', 'feed', 'recording', 'tv', 'em', 'telephony', 'apis', 'move', 'img', 'predictable', 'scan', 'l', 'yesterday', 'requirement', 'dynamic', 'position', 'numbers', 'virus', 'spring', 'face', 'tip', 'usa', 'jrockit', 'money', 'extend', 'short', 'blm', 'kernelmode', 'monitoring', 'quality', 'tor', 'il', 'temperature', 'luck', 'adminphp', 'cart', 'hpa', 'u', 'alerts', 'behavior', 'lan', 'writing', 'wrong', 'enough', 'clouds', 'maliciously', 'siemens', 'commit', 'older', 'loss', 'movie', 'invoke', 'asterisk', 'hub', 'unit', 'chinese', 'chance', 'avenue', 'hope', 'hpux', 'logic', 'ep', 'menu', 'staring', 'march', 'three', 'thing', 'seasonal', 'powerpoint', 'warfare', 'files', 'h', 'kerberos', 'smtp', 'rce', 'finally', 'color', 'step', 'russian', 'track', 'learning', 'engineer', 'loginphp', 'pa', 'category', 'lite', 'mr', 'date', 'landing', 'usg', 'grant', 'ac', 'shopping', 'international', 'brute', 'mark', 'openstack', 'conversion', 'chakra', 'manageengine', 'computing', 'stay', 'lifecycle', 'persuade', 'ssrf', 'alpha', 'focus', 'super', 'china', 'ddos', 'offset', 'unencrypted', 'procedure', 'violation', 'samba', 'safety', 'gpu', 'ie', 'av', 'river', 'senior', 'repost', 'blink', 'gdi', 'quit', 'dialog', 'underflow', 'cp', 'bi', 'visual', 'hot', 'ma', 'law', 'fragment', 'item', 'thread', 'flood', 'operator', 'across', 'car', 'taking', 'nsa', 'chunk', 'nature', 'unintended', 'fake', 'nurse', 'released', 'question', 'others', 'officer', 'bundle', 'either', 'technical', 'assistant', 'distribution', 'deep', 'favorite', 'asking', 'lot', 'slash', 'win', 'typically', 'radio', 'xr', 'lower', 'campaign', 'webapps', 'unexpected', 'networks', 'achieve', 'ii', 'pt', 'research', 'deserialization', 'true', 'earthquake', 'cannot', 'referer', 'whose', 'building', 'bugtraq', 'portland', 'catid', 'wincc', 'bgp', 'yet', 'credit', 'together', 'india', 'perfect', 'kingdom', 'nervous', 'ctinglobal', 'teammates', 'metadata', 'count', 'registration', 'mx', 'citrix', 'iis', 'fingerprint', 'perl', 'factory', 'audit', 'left', 'shy', 'applicant', 'ago', 'iframe', 'picture', 'william', 'newyork', 'correctly', 'suffer', 'author', 'previously', 'tree', 'price', 'youtube', 'offbyone', 'imap', 'flow', 'grid', 'head', 'daytoday', 'possibility', 'cwe', 'branch', 'worker', 'backdoor', 'ave', 'sunset', 'rv', 'messaging', 'recovery', 'dump', 'final', 'appealing', 'webmail', 'enter', 'maintenance', 'scada', 'god', 'construct', 'guess', 'important', 'training', 'cnet', 'render', 'mediaserver', 'plugins', 'ultimate', 'sure', 'versions', 'releases', 'heres', 'decoder', 'unicode', 'per', 'spam', 'shift', 'threats', 'bruteforce', 'stable', 'schneider', 'month', 'mediawiki', 'baby', 'maximo', 'corporate', 'soon', 'acl', 'domino', 'rendering', 'parts', 'utc', 'converter', 'premium', 'country', 'wa', 'garden', 'makes', 'boundary', 'locate', 'topic', 'yahoo', 'amazon', 'believe', 'someone', 'tim', 'technician', 'covid', 'terminate', 'cryptocurrency', 'compatibility', 'usage', 'destination', 'pop', 'behind', 'wearable', 'transport', 'houston', 'reply', 'modicon', 'intercept', 'fortinet', 'total', 'pre', 'dangerous', 'listen', 'shockwave', 'correct', 'browsing', 'lenovo', 'abuse', 'touch', 'galaxy', 'fbi', 'took', 'serialize', 'resultant', 'initial', 'publish', 'pool', 'mccullough', 'znla', 'cscve', 'though', 'sale', 'susceptible', 'cybozu', 'andor', 'visiting', 'storm', 'portion', 'connector', 'guard', 'darkreading', 'todays', 'puppet', 'reuse', 'leaf', 'preview', 'normal', 'warehouse', 'king', 'mind', 'ucs', 'telepresence', 'tab', 'nest', 'bea', 'originally', 'kaspersky', 'press', 'lockdown', 'trying', 'webaccess', 'mybb', 'hyperv', 'emulator', 'specifically', 'authority', 'treat', 'mask', 'rising', 'story', 'island', 'fulfillment', 'overlap', 'subsequent', 'manipulation', 'electronics', 'detect', 'classified', 'supervisor', 'coffee', 'theres', 'permit', 'ox', 'zoho', 'legitimate', 'botnet', 'months', 'angeles', 'dom', 'macro', 'volume', 'break', 'course', 'challenge', 'wi', 'chicago', 'jdk', 'webserver', 'consume', 'gif', 'soap', 'reliable', 'postgresql', 'early', 'university', 'scheme', 'giving', 'signedness', 'tcpdump', 'commerce', 'child', 'water', 'enjoy', 'jsp', 'infosphere', 'coldfusion', 'git', 'cup', 'pay', 'trump', 'guestbook', 'mojave', 'transaction', 'timing', 'el', 'yes', 'education', 'penetration', 'append', 'primavera', 'gem', 'blackberry', 'worldreadable', 'uid', 'pattern', 'produce', 'restore', 'button', 'substring', 'license', 'insight', 'october', 'pi', 'ok', 'states', 'cgibincvenam', 'ecginamecve', 'keyboard', 'mall', 'highly', 'energy', 'recent', 'fresh', 'mdt', 'nothing', 'sanitization', 'phpbb', 'mime', 'replay', 'enforcement', 'ace', 'room', 'heart', 'transmit', 'transmission', 'july', 'quake', 'plan', 'near', 'industry', 'chicken', 'club', 'russia', 'carolina', 'webcenter', 'config', 'fast', 'sb', 'away', 'hours', 'awesome', 'zdnet', 'incl', 'navigation', 'nodejs', 'beginning', 'meet', 'far', 'living', 'said', 'started', 'proud', 'directions', 'afternoon', 'src', 'pid', 'replace', 'docker', 'isnt', 'harbor', 'affairs', 'eval', 'adminindexphp', 'moxa', 'serverside', 'elf', 'desk', 'reverse', 'lab', 'crypto', 'fargo', 'uris', 'calculation', 'resolve', 'prevention', 'pr', 'ways', 'recursion', 'dashboard', 'messenger', 'isc', 'dm', 'y', 'ups', 'kts', 'utf', 'selection', 'given', 'door', 'science', 'flaws', 'enumerate', 'sufficiently', 'unsafe', 'wp', 'helper', 'bb', 'reach', 'strong', 'mo', 'lapd', 'barometer', 'ipq', 'authorize', 'phpnuke', 'speciallycrafted', 'lang', 'main', 'weeks', 'hotfix', 'adjacent', 'credential', 'generator', 'february', 'magazine', 'sky', 'pretty', 'golf', 'kids', 'normally', 'netweaver', 'april', 'beyond', 'works', 'japan', 'onetoone', 'automobile', 'describe', 'deploy', 'sheet', 'spectrum', 'smartphones', 'greater', 'streaming', 'practical', 'peace', 'asp', 'revision', 'counter', 'actually', 'temp', 'informational', 'norton', 'successfully', 'label', 'pin', 'middle', 'green', 'nb', 'userid', 'hyperion', 'publication', 'libtiff', 'define', 'sterling', 'scanning', 'words', 'means', 'friend', 'feel', 'tuesday', 'tomorrow', 'cscvf', 'blacklist', 'interact', 'extra', 'opensource', 'welcome', 'beauty', 'done', 'provision', 'binutils', 'scenario', 'agile', 'atlassian', 'least', 'star', 'accounts', 'customers', 'affected', 'mambo', 'impersonate', 'portfolio', 'january', 'azure', 'cool', 'labor', 'hill', 'termination', 'winksys', 'presence', 'editing', 'automatically', 'talk', 'ride', 'cvssavnaclprnuirscchilan', 'spotfire', 'therefore', 'trace', 'plain', 'adapter', 'continue', 'didnt', 'whats', 'situation', 'study', 'exposed', 'products', 'irc', 'integrator', 'broker', 'squid', 'sample', 'longer', 'cards', 'peaceful', 'layout', 'cipher', 'bound', 'jet', 'combination', 'toolkit', 'skin', 'ask', 'bay', 'researchers', 'issues', 'cid', 'computation', 'peer', 'self', 'atlanta', 'reality', 'pdx', 'initialization', 'aslr', 'addition', 'aws', 'along', 'america', 'updates', 'jburnsconsult', 'sundayfunday', 'backslash', 'bmp', 'fixation', 'png', 'asr', 'exec', 'bus', 'dr', 'went', 'gust', 'initiate', 'rdbms', 'nfs', 'builder', 'etc', 'happen', 'manufacturing', 'contenttype', 'handshake', 'jd', 'cruise', 'installing', 'signal', 'approach', 'surveillance', 'apt', 'fight', 'wants', 'leadwithgiants', 'photos', 'allied', 'segment', 'edwards', 'organization', 'corporation', 'major', 'cso', 'attackerspecified', 'excessive', 'sophos', 'almost', 'town', 'gets', 'beer', 'divisionsquawk', 'chakracore', 'parent', 'forge', 'ext', 'rock', 'justice', 'breakfast', 'companies', 'rename', 'duplicate', 'convert', 'separate', 'recover', 'clone', 'startup', 'repair', 'forget', 'quarantine', 'whatsapp', 'sw', 'five', 'dog', 'valley', 'targets', 'came', 'felt', 'cvssavnaclprhuinsucninah', 'versioncode', 'prompt', 'tplink', 'iso', 'analyzer', 'automatic', 'album', 'kill', 'choice', 'sometimes', 'rn', 'cvs', 'siplus', 'xnview', 'routine', 'pl', 'confidential', 'deliver', 'wait', 'tell', 'grand', 'thezigziglar', 'kelly', 'attach', 'alter', 'irfanview', 'reject', 'entire', 'front', 'receiverstocker', 'compress', 'wndrv', 'ap', 'j', 'az', 'wnd', 'miles', 'realnetworks', 'ping', 'purpose', 'cyberwar', 'friday', 'cscvc', 'directive', 'mapping', 'wire', 'ship', 'architecture', 'archives', 'metasploit', 'buy', 'z', 'takes', 'mdmm', 'vrcspcpwe', 'faulting', 'otherwise', 'swap', 'serial', 'smartphone', 'usgs', 'cvssavnaclprnuirscclilan', 'alarm', 'popular', 'mountain', 'packetstorm', 'tweetjukebox', 'tar', 'convince', 'xc', 'printing', 'magic', 'fedora', 'pp', 'offer', 'powerful', 'issuewlb', 'passwords', 'foundry', 'although', 'es', 'expert', 'american', 'stand', 'blockchain', 'advanced', 'evening', 'lovely', 'referrals', 'icmp', 'clamav', 'listening', 'mini', 'forensics', 'solutions', 'calculate', 'readonly', 'entering', 'kde', 'redirection', 'bsod', 'ak', 'likely', 'anything', 'remember', 'tn', 'lost', 'brewing', 'looks', 'stolen', 'women', 'trailing', 'bugzilla', 'dispute', 'panos', 'moderate', 'august', 'partner', 'speed', 'sweet', 'needs', 'nessusorgpluginsindex', 'phpviewsingleid', 'comes', 'downtown', 'tmp', 'assume', 'leakage', 'ge', 'kind', 'georgia', 'wrf', 'wlan', 'pulse', 'idea', 'worth', 'lol', 'mq', 'clickjacking', 'documentum', 'hotel', 'vision', 'huge', 'bring', 'experts', 'guys', 'declaration', 'relationship', 'answer', 'fully', 'square', 'travel', 'trail', 'vs', 'launches', 'ipsec', 'ethereal', 'elevate', 'incoming', 'relay', 'asus', 'collaborative', 'avoid', 'thought', 'finance', 'george', 'men', 'zeroday', 'scmagazine', 'forwarding', 'jira', 'ntp', 'sort', 'vr', 'rise', 'las', 'enjoying', 'qccr', 'listener', 'cascade', 'keyword', 'particular', 'curl', 'native', 'instagram', 'deal', 'growing', 're', 'broken', 'browserbased', 'cn', 'hmi', 'ee', 'glibc', 'openbsd', 'auth', 'broadcast', 'arm', 'unity', 'mt', 'cable', 'hello', 'severe', 'coaching', 'interviews', 'businesses', 'pain', 'dinner', 'snv', 'hd', 'opensuse', 'honor', 'vehicle', 'season', 'wont', 'applications', 'seen', 'infosecnewsbot', 'needed', 'cloudy', 'csv', 'introduce', 'scanner', 'keywords', 'increase', 'skype', 'serve', 'github', 'airport', 'half', 'pharmacy', 'ontario', 'cxsecurity', 'threatpost', 'width', 'pipe', 'mobility', 'official', 'hadoop', 'whole', 'dollar', 'patches', 'ill', 'customerservice', 'exploitationproduct', 'dividebyzero', 'horde', 'modem', 'saml', 'expansion', 'banner', 'mit', 'student', 'bulletin', 'conference', 'mostly', 'registered', 'ajax', 'mu', 'maximum', 'waiting', 'four', 'fraud', 'girl', 'sea', 'prince', 'ceo', 'wanted', 'physician', 'versionname', 'oops', 'production', 'moment', 'tips', 'types', 'reachable', 'contentlength', 'libc', 'instant', 'legacy', 'begin', 'brand', 'ice', 'tenablecompluginsnessus', 'cms', 'administer', 'tftp', 'shutdown', 'ce', 'sa', 'sony', 'theathelite', 'callback', 'xorg', 'choose', 'modern', 'ahead', 'continues', 'interpret', 'unsigned', 'comparison', 'maintain', 'salt', 'pe', 'act', 'patient', 'ct', 'military', 'cyberexaminer', 'exe', 'photoshop', 'unlock', 'realtime', 'higher', 'journal', 'da', 'spy', 'massive', 'court', 'exists', 'feeling', 'securityweek', 'nport', 'ownership', 'catalyst', 'supplying', 'otrs', 'commandline', 'ignore', 'notice', 'analyst', 'copying', 'qradar', 'owncloud', 'playlist', 'rfc', 'defeat', 'region', 'playing', 'theft', 'pick', 'crime', 'offers', 'pentest', 'feels', 'fetch', 'respond', 'rather', 'clean', 'di', 'gift', 'restaurant', 'falls', 'partly', 'targeted', 'vegas', 'fort', 'vrcspcb', 'optimizer', 'rx', 'jazz', 'su', 'estate', 'steps', 'leave', 'staff', 'late', 'un', 'delicious', 'maryland', 'worldwritable', 'aspnet', 'nat', 'sudo', 'statistics', 'technique', 'soft', 'et', 'difference', 'woman', 'gst', 'correspond', 'enterpriseone', 'httpd', 'swf', 'wrapper', 'poll', 'openssh', 'ecommerce', 'trade', 'nv', 'dream', 'scientific', 'age', 'cold', 'nevada', 'warns', 'based', 'naked', 'sites', 'quest', 'revolution', 'fitness', 'helpnetsecurity', 'saturday', 'excited', 'apqau', 'netscape', 'passing', 'invite', 'aim', 'november', 'progress', 'sell', 'pci', 'programming', 'emergency', 'ai', 'wb', 'brooklyn', 'hour', 'brunch', 'less', 'intranet', 'openview', 'zfs', 'atom', 'vnc', 'standalone', 'vlc', 'blind', 'ss', 'rhel', 'push', 'showing', 'ia', 'rapid', 'mean', 'college', 'shows', 'netbsd', 'instruction', 'prone', 'intent', 'tracker', 'cast', 'horizon', 'anywhere', 'alto', 'silver', 'song', 'serious', 'orange', 'stock', 'socialmedia', 'secrets', 'irix', 'activematrix', 'phantompdf', 'utilize', 'disconnect', 'advantech', 'tcpip', 'tunnel', 'certification', 'shadow', 'bill', 'dallas', 'firm', 'rules', 'ohio', 'snapdragonhighmed', 'tecal', 'pathnames', 'homepage', 'decoding', 'column', 'gnome', 'popup', 'graphicsmagick', 'portable', 'booking', 'palo', 'ps', 'watching', 'starbucks', 'virginia', 'yall', 'crossorigin', 'wpadminadminphp', 'recursive', 'nx', 'deny', 'pivotal', 'rails', 'false', 'manual', 'max', 'ocean', 'lync', 'overallread', 'arf', 'apm', 'libstagefright', 'garoon', 'bpm', 'cx', 'viewing', 'enhance', 'designer', 'essential', 'eu', 'hospital', 'british', 'yo', 'boy', 'edt', 'freight', 'rhelpnetsecu', 'wikileaks', 'weve', 'blessed', 'hills', 'userspace', 'preference', 'esxi', 'wiki', 'icon', 'linksys', 'mate', 'cd', 'xl', 'independent', 'survey', 'despite', 'photography', 'servers', 'latestsecuritynews', 'msg', 'codec', 'xpdf', 'partition', 'openjdk', 'ghostscript', 'dev', 'satellite', 'village', 'lunch', 'stoner', 'breaches', 'tstorm', 'plm', 'exceed', 'releasep', 'synology', 'guessing', 'detail', 'demo', 'former', 'wall', 'fashion', 'john', 'lyn', 'young', 'cocorahs', 'ikev', 'asn', 'symbolic', 'rar', 'krb', 'investor', 'unquoted', 'signing', 'interactive', 'positive', 'couple', 'realestate', 'esb', 'specialist', 'opdevsec', 'goes', 'uses', 'hacks', 'opensolaris', 'useragent', 'parallel', 'decryption', 'rich', 'practice', 'death', 'trip', 'cake', 'jesse', 'millions', 'danvforbes', 'beginners', 'stories', 'miami', 'secospace', 'multilanguage', 'repeatedly', 'plc', 'actor', 'seed', 'december', 'evolution', 'hold', 'purchase', 'tear', 'scam', 'databreach', 'hum', 'flowers', 'omit', 'mybulletinboard', 'mediatek', 'pam', 'rdp', 'par', 'closing', 'round', 'crazy', 'xoops', 'libxml', 'nonce', 'tc', 'upnp', 'hypervisor', 'often', 'artist', 'bike', 'quotes', 'cio', 'michigan', 'bxbus', 'phpkb', 'nicobar', 'ise', 'servicing', 'vbscript', 'locking', 'addon', 'clientside', 'inventory', 'powershell', 'vote', 'teacher', 'planet', 'growth', 'q', 'creek', 'shot', 'canada', 'chase', 'missing', 'asos', 'hitachi', 'rb', 'qfx', 'uncontrolled', 'scheduler', 'protector', 'loader', 'quantum', 'wide', 'ipa', 'mining', 'spyware', 'hey', 'computers', 'simphony', 'crossdomain', 'ike', 'opportunistic', 'replication', 'compile', 'blank', 'diagnostics', 'catalog', 'candidate', 'batch', 'severity', 'canvas', 'newsletter', 'phoenix', 'creative', 'podcast', 'ha', 'thinking', 'gorgeous', 'calls', 'lookup', 'qcaau', 'nonexistent', 'alternate', 'hdf', 'padding', 'inspection', 'locally', 'environmental', 'doc', 'sierra', 'bash', 'residential', 'federal', 'havent', 'chadha', 'widget', 'relative', 'bios', 'ssltls', 'transition', 'raw', 'term', 'governance', 'lg', 'recently', 'minutes', 'shipping', 'catch', 'guy', 'slowly', 'else', 'pizza', 'jpmorgan', 'netware', 'cscvb', 'ipswitch', 'interrupt', 'inappropriate', 'npm', 'sqlite', 'refer', 'sep', 'actual', 'schedule', 'theyre', 'biggest', 'exploitdb', 'members', 'plans', 'defaultasp', 'wlc', 'groupwise', 'bfd', 'frontend', 'encounter', 'pair', 'background', 'op', 'summary', 'nm', 'cut', 'die', 'truck', 'election', 'boston', 'emails', 'grateful', 'records', 'pennsylvania', 'wonderful', 'cscvg', 'signatureorsystem', 'unexpectedly', 'eap', 'svn', 'kvm', 'nagios', 'zyxel', 'effort', 'dsa', 'reason', 'ks', 'youve', 'suffers', 'certified', 'authenticated', 'called', 'racism', 'nyc', 'bread', 'unattended', 'decode', 'nip', 'mahara', 'merge', 'poppler', 'permanent', 'fork', 'paypal', 'liberty', 'des', 'con', 'introduction', 'targeting', 'messages', 'colorado', 'louis', 'thunderstorm', 'vrcb', 'sgi', 'namespace', 'meta', 'snapshot', 'documentation', 'jar', 'voip', 'cell', 'pixel', 'fact', 'panda', 'innovation', 'especially', 'hand', 'army', 'challenges', 'books', 'employees', 'iwebstatus', 'colocated', 'libbfd', 'netscaler', 'height', 'artifex', 'ipod', 'django', 'period', 'association', 'conflict', 'jr', 'president', 'itmedia', 'angelessquawk', 'mailbox', 'mod', 'assets', 'collision', 'cert', 'simply', 'matrix', 'legal', 'heights', 'nigeria', 'fixes', 'provides', 'globalsecuritynews', 'kellyjobs', 'kellyservices', 'logout', 'ssid', 'readwrite', 'omnibox', 'sid', 'workspace', 'observe', 'cognos', 'sensor', 'appropriate', 'oauth', 'definition', 'fa', 'electronic', 'centre', 'ut', 'agency', 'cia', 'scoopit', 'created', 'toronto', 'attackercontrolled', 'cscuv', 'newsphp', 'acls', 'workflow', 'freetype', 'pv', 'dnp', 'larger', 'jasper', 'repeat', 'sim', 'phase', 'accounting', 'nakedsecurity', 'leaked', 'yeah', 'hair', 'hike', 'rle', 'sendmail', 'sufficient', 'xmlrpc', 'csp', 'jpg', 'membership', 'updating', 'ru', 'primary', 'cryptography', 'september', 'das', 'strategy', 'fulldisclosure', 'children', 'sinamics', 'dbus', 'uaa', 'abort', 'libav', 'ansible', 'vbulletin', 'dirl', 'actionable', 'sync', 'intrusion', 'fsecure', 'removal', 'ig', 'pic', 'union', 'cafe', 'paper', 'walking', 'weekly', 'oreilly', 'smile', 'own', 'usercontrolled', 'scalance', 'invision', 'readable', 'interpretation', 'veritas', 'rmi', 'splunk', 'replacing', 'migration', 'optimization', 'fill', 'robot', 'landscape', 'understand', 'africa', 'protests', 'hits', 'claims', 'anniversary', 'dewp', 'sdks', 'cscvd', 'scm', 'insecurely', 'radius', 'threads', 'carefully', 'navigate', 'blocking', 'extreme', 'amd', 'evidence', 'illegal', 'laptop', 'cost', 'raspberry', 'fish', 'chief', 'kitchen', 'cyberspace', 'contains', 'worlds', 'technologies', 'hidden', 'javafx', 'chipsets', 'syntax', 'assignment', 'exponent', 'mitigate', 'receiver', 'spa', 'scale', 'avast', 'effective', 'compliance', 'finding', 'spot', 'wish', 'farm', 'dance', 'tennessee', 'obama', 'usn', 'crafted', 'fighting', 'moving', 'zerowaste', 'funday', 'subsequently', 'recipient', 'tia', 'memcpy', 'videolan', 'fpx', 'refresh', 'cactus', 'ntlm', 'mitigation', 'echo', 'probe', 'spark', 'mission', 'workout', 'waste', 'known', 'hate', 'pictures', 'syslog', 'mantisbt', 'qm', 'innodb', 'hcm', 'priority', 'selling', 'youll', 'interesting', 'sundays', 'spreadsheet', 'nickname', 'txt', 'codesys', 'specification', 'exynos', 'openid', 'dp', 'avatar', 'avi', 'eclipse', 'berkeley', 'mirror', 'jquery', 'mass', 'ky', 'wine', 'hollywood', 'banks', 'district', 'cyberwarbooks', 'questions', 'interview', 'providers', 'detected', 'games', 'nontstm', 'arp', 'regression', 'postscript', 'dv', 'ov', 'resolution', 'instructions', 'decision', 'posting', 'ipad', 'son', 'infosecmag', 'wannacry', 'chuckdbrooks', 'worldwide', 'cscuh', 'filtration', 'plone', 'openxchange', 'diagnostic', 'dictionary', 'ending', 'fm', 'verizon', 'fo', 'leader', 'exposes', 'published', 'students', 'spent', 'rtsp', 'scope', 'pdfium', 'htaccess', 'webdav', 'ud', 'ole', 'admins', 'nova', 'loads', 'recognize', 'forensic', 'fear', 'saw', 'illinois', 'reveals', 'australia', 'adds', 'firms', 'truncate', 'asyncos', 'tmm', 'openshift', 'compression', 'sdwan', 'represent', 'poisoning', 'tp', 'relevant', 'broadband', 'reflection', 'ch', 'planning', 'brother', 'columbia', 'poc', 'lots', 'minute', 'maybe', 'moon', 'saint', 'santa', 'thousands', 'missed', 'feedwwwthere', 'theregister', 'rnetsec', 'madison', 'skills', 'added', 'congratulations', 'cream', 'exif', 'isupport', 'lowprivileged', 'glassfish', 'ipc', 'yaml', 'orchestrator', 'extraction', 'aruba', 'publicly', 'remain', 'stage', 'western', 'eye', 'fall', 'everyday', 'sans', 'techniques', 'cscus', 'mosconfigabsolutepath', 'exhaust', 'xerox', 'gnulinux', 'browse', 'combine', 'archer', 'vp', 'gen', 'iv', 'mid', 'slow', 'breaking', 'nw', 'sse', 'eb', 'stuff', 'italy', 'motivation', 'gonna', 'celebrate', 'sunrise', 'salad', 'insufficiently', 'binding', 'pidgin', 'wizard', 'qnap', 'esa', 'sidechannel', 'disruption', 'pgp', 'subscribe', 'raise', 'employee', 'speech', 'spend', 'organic', 'closure', 'tour', 'french', 'columbus', 'phones', 'seems', 'results', 'skilledtrade', 'multicast', 'configphp', 'laserjet', 'viewphp', 'asm', 'override', 'exiv', 'undocumented', 'subscriber', 'vms', 'immediately', 'material', 'demand', 'leaving', 'sleep', 'hole', 'six', 'billion', 'tea', 'episode', 'bugs', 'boys', 'taken', 'events', 'girls', 'loving', 'facilitate', 'symlinks', 'vrcsph', 'compose', 'groupware', 'misuse', 'activate', 'netiq', 'kubernetes', 'bitdefender', 'webapp', 'among', 'palm', 'non', 'movement', 'li', 'piece', 'hiking', 'cheese', 'iran', 'truth', 'finished', 'dong', 'profilephp', 'cscuu', 'fip', 'zerolength', 'pn', 'visio', 'expire', 'jasperreports', 'inconsistent', 'confirm', 'symbol', 'translation', 'fleet', 'delta', 'necessary', 'letter', 'crack', 'stealing', 'department', 'busy', 'academy', 'fine', 'indian', 'freedom', 'soul', 'que', 'espionage', 'gone', 'apples', 'pts', 'ipados', 'phpbbrootpath', 'bitmap', 'emulation', 'wsa', 'gd', 'openjpeg', 'catalina', 'modbus', 'siem', 'launching', 'htc', 'quickly', 'insurance', 'quite', 'seeing', 'crew', 'chocolate', 'ads', 'terrible', 'istore', 'cscuy', 'cscue', 'sdp', 'movable', 'alias', 'uniscribe', 'rtf', 'hana', 'skip', 'predict', 'netapp', 'vault', 'advantage', 'trial', 'competition', 'ml', 'ic', 'outdoor', 'del', 'forest', 'agree', 'grill', 'queen', 'lane', 'arrested', 'securityfocuscombid', 'digitalid', 'opportunities', 'creating', 'philadelphia', 'springs', 'registerphp', 'cscut', 'cscvi', 'modulesphp', 'jmx', 'websocket', 'downloadphp', 'rockwell', 'indicate', 'sametime', 'wpadminadminajaxphp', 'newline', 'lending', 'libcurl', 'dimension', 'broadcom', 'elastic', 'delay', 'weakness', 'concert', 'stats', 'aid', 'completely', 'grow', 'med', 'cyberattack', 'lazyconsultant', 'networkworld', 'rolls', 'sports', 'pride', 'hes', 'stocking', 'showers', 'decided', 'chumidity', 'vulndisco', 'strut', 'jetbrains', 'timeout', 'opentype', 'revoke', 'sender', 'writable', 'zte', 'bigfix', 'subscription', 'xiaomi', 'offline', 'cu', 'conversation', 'flexible', 'zoom', 'tiny', 'percent', 'shut', 'chip', 'strength', 'trading', 'uber', 'brown', 'cw', 'korea', 'cyberwarfare', 'sold', 'vibes', 'cscuz', 'cscuw', 'cucm', 'directx', 'advertisement', 'bootloader', 'syn', 'bookmark', 'clipboard', 'xmpp', 'automate', 'qt', 'interconnect', 'garbage', 'nokia', 'prepare', 'ban', 'plant', 'tax', 'golden', 'paul', 'grab', 'nearly', 'trends', 'rights', 'feet', 'rss', 'shit', 'bbq', 'saic', 'cscur', 'srg', 'hvm', 'aironet', 'skia', 'officescan', 'inline', 'unsanitized', 'manually', 'interpreter', 'vcenter', 'ec', 'rust', 'reserve', 'tr', 'supporting', 'japanese', 'francisco', 'james', 'wedding', 'zdi', 'oil', 'eat', 'mom', 'culture', 'securitybloggernews', 'bag', 'images', 'masks', 'sunshine', 'cdl', 'autocomplete', 'abnormal', 'emf', 'ichitaro', 'arcserve', 'libvirt', 'wago', 'ez', 'lm', 'bmc', 'foreman', 'channels', 'expand', 'quiz', 'unusual', 'reportedly', 'awareness', 'german', 'natural', 'tried', 'protecting', 'thehackersnews', 'exploitdbcomexploits', 'falling', 'fave', 'heard', 'opened', 'scx', 'clientserver', 'renderer', 'eccube', 'xslt', 'unavailable', 'nnm', 'whitelist', 'evaluate', 'submission', 'digest', 'zen', 'unwanted', 'mix', 'battle', 'sector', 'spain', 'drink', 'boss', 'securing', 'wired', 'launched', 'resources', 'cars', 'ones', 'designed', 'scattered', 'worship', 'decompression', 'opc', 'webui', 'superuser', 'prefix', 'explicitly', 'autodesk', 'bbcode', 'interim', 'vague', 'upstream', 'prototype', 'commons', 'wan', 'visible', 'motorola', 'eventually', 'onto', 'twice', 'row', 'train', 'foreign', 'peak', 'forever', 'diego', 'shoot', 'nh', 'hands', 'eyes', 'cyberattacks', 'exploiting', 'victims', 'keys', 'clients', 'videos', 'organizations', 'compromised', 'turkey', 'georgefloyd', 'subjectaltname', 'cscux', 'mdmc', 'mpeg', 'thereby', 'itemid', 'invocation', 'winamp', 'arbitrarily', 'rbk', 'constraint', 'timestamp', 'upd', 'wm', 'cab', 'serialization', 'guardium', 'pump', 'suggest', 'architect', 'destroy', 'effect', 'castle', 'epic', 'announce', 'pub', 'singapore', 'flight', 'keeping', 'genesis', 'institute', 'understanding', 'lord', 'finds', 'risks', 'problems', 'journey', 'shes', 'ncve', 'cscuq', 'loggedin', 'inadequate', 'dolibarr', 'subversion', 'sl', 'builtin', 'sonicwall', 'fw', 'plane', 'campus', 'advisor', 'wrap', 'led', 'lose', 'fr', 'tune', 'stone', 'camp', 'handbook', 'goals', 'announces', 'charlotte', 'pem', 'cscuj', 'squirrelmail', 'centreon', 'sctp', 'imageio', 'nextcloud', 'cerp', 'taxonomy', 'plesk', 'netbackup', 'fortios', 'msn', 'rebel', 'pipeline', 'regardless', 'enumeration', 'presentation', 'trap', 'nmap', 'maker', 'gb', 'eset', 'sit', 'clinical', 'boost', 'michael', 'european', 'film', 'baltimore', 'talking', 'connected', 'reasons', 'allowed', 'ethical', 'affects', 'closed', 'fuck', 'thermo', 'facilitiesmgmt', 'edtstn', 'wpadminoptionsgeneralphp', 'rbr', 'cscug', 'rennell', 'unaffected', 'callmanager', 'sso', 'href', 'receipt', 'vx', 'passcode', 'xi', 'switching', 'rating', 'openvpn', 'motion', 'collector', 'auction', 'succeed', 'gentoo', 'burning', 'responsible', 'reduce', 'depth', 'circle', 'allen', 'serving', 'strategic', 'arts', 'wake', 'yoga', 'dad', 'insider', 'europe', 'shellcode', 'coast', 'leaders', 'troj', 'rnakedsecuri', 'features', 'includes', 'cases', 'louisiana', 'richmond', 'spade', 'workcentre', 'truncation', 'sco', 'dependency', 'hotspot', 'saving', 'pix', 'multi', 'inspector', 'flex', 'ultra', 'gps', 'jump', 'gaming', 'remains', 'overview', 'colors', 'till', 'cute', 'absolutely', 'ireland', 'routers', 'built', 'posts', 'stored', 'changes', 'spying', 'investing', 'schools', 'hail', 'dreams', 'definitely', 'loves', 'gotta', 'cvssavnaclprnuinsuclinan', 'collateral', 'originate', 'webgl', 'setgid', 'edirectory', 'avaya', 'telephone', 'downgrade', 'silverlight', 'stale', 'faq', 'snort', 'slave', 'mouse', 'carry', 'throw', 'seem', 'hr', 'wasnt', 'nation', 'comprehensive', 'wife', 'starts', 'appreciate', 'spotted', 'born', 'rtacu', 'whm', 'cscud', 'adminheaderphp', 'foscam', 'dynamics', 'touchscreen', 'nginx', 'constant', 'logo', 'ghost', 'si', 'pull', 'recipe', 'worst', 'heat', 'investigation', 'reuters', 'charter', 'spread', 'basics', 'arizona', 'massachusetts', 'overnight', 'turned', 'googles', 'asked', 'written', 'brings', 'fisher', 'brothers', 'pink', 'prtl', 'isakmp', 'loginasp', 'protos', 'kdc', 'checksum', 'opcode', 'captcha', 'qts', 'solr', 'libarchive', 'caller', 'aol', 'chart', 'radare', 'knowing', 'ring', 'isis', 'llc', 'observer', 'steam', 'arent', 'bed', 'healthy', 'tornado', 'israel', 'turns', 'concerns', 'infected', 'reported', 'fixed', 'matters', 'changing', 'orders', 'baptist', 'fathers', 'tsm', 'rvw', 'phpinfo', 'syscall', 'smbv', 'markup', 'timer', 'wildcard', 'zimbra', 'graphite', 'ax', 'unc', 'kiss', 'unprotected', 'openemr', 'solarwinds', 'behalf', 'rh', 'micros', 'gadget', 'antimalware', 'silent', 'david', 'swipe', 'ball', 'sorry', 'developers', 'networkworldcomarticle', 'infosecuritymagazine', 'floyd', 'lady', 'bronx', 'austin', 'wy', 'outofbound', 'cscui', 'iologik', 'lsa', 'jvm', 'cors', 'xforwardedfor', 'neutralization', 'jabber', 'viewpoint', 'mounting', 'arcsight', 'bento', 'nfc', 'libreoffice', 'disrupt', 'curve', 'individual', 'nextgeneration', 'desire', 'int', 'unless', 'notebook', 'slide', 'complex', 'atm', 'miner', 'ri', 'wave', 'rapidly', 'mike', 'flower', 'driving', 'helping', 'rally', 'mile', 'patio', 'tweetjukeboxcom', 'infosecurity', 'bleepingcomputercomnewssecurity', 'exploring', 'torn', 'cscum', 'hrms', 'nonstandard', 'frp', 'ftd', 'truetype', 'sparc', 'stdu', 'esx', 'notify', 'pcre', 'avamar', 'cumulative', 'marketplace', 'hook', 'creator', 'carbon', 'gear', 'surface', 'division', 'capital', 'wing', 'worm', 'cracking', 'bro', 'dead', 'bounty', 'summit', 'fox', 'seattle', 'plaza', 'couldnt', 'germany', 'equifax', 'announced', 'exploited', 'mother', 'countries', 'groups', 'opens', 'gives', 'operating', 'computerworld', 'stunning', 'glad', 'annotation', 'spr', 'constructor', 'anyconnect', 'abb', 'dtls', 'initiation', 'schema', 'libming', 'rpm', 'impersonation', 'entropy', 'edd', 'strict', 'communicate', 'wpa', 'strip', 'er', 'alternative', 'comfort', 'drawing', 'contributor', 'paint', 'friendly', 'wonder', 'goal', 'drone', 'mine', 'explore', 'mina', 'somewhere', 'magnitude', 'mortgage', 'ground', 'named', 'laws', 'cyberespionage', 'distributed', 'oklahoma', 'homemade', 'lessons', 'happiness', 'celebrating', 'nne', 'lagos', 'wnrv', 'sshd', 'exclude', 'orderby', 'wav', 'malloc', 'gnutls', 'passwd', 'reporter', 'ieee', 'comodo', 'ra', 'transit', 'acquire', 'isolation', 'transformation', 'triple', 'develop', 'border', 'nobody', 'buddy', 'pie', 'sense', 'grade', 'gmail', 'glass', 'speak', 'cook', 'nuclear', 'underground', 'excellent', 'securitytube', 'beat', 'faces', 'hitb', 'told', 'cscun', 'setcookie', 'icq', 'cwd', 'libxaac', 'mg', 'clearpass', 'pfc', 'pg', 'activation', 'negotiation', 'axis', 'poison', 'graph', 'equal', 'replacement', 'mc', 'effectively', 'clip', 'pwnown', 'defender', 'assurance', 'po', 'mongodb', 'vi', 'abc', 'appointment', 'lazy', 'happening', 'linkedin', 'holiday', 'gdpr', 'gym', 'orlando', 'wsw', 'related', 'snowden', 'fucking', 'mirai', 'places', 'hamilton', 'truly', 'regional', 'tampa', 'tstm', 'forplay', 'chicos', 'deadlock', 'konqueror', 'stylesheet', 'derive', 'nvlddmkmsys', 'realm', 'issuing', 'dhcpv', 'informix', 'unsupported', 'ppp', 'owa', 'tampering', 'serendipity', 'traverse', 'inadvertently', 'ntpd', 'mariadb', 'ds', 'cbc', 'sentinel', 'ops', 'discussion', 'principal', 'transform', 'warn', 'cycle', 'direction', 'seo', 'math', 'charge', 'assembly', 'bot', 'shout', 'tripwire', 'earth', 'hire', 'brazil', 'hall', 'revealed', 'hortonworks', 'spending', 'dogs', 'whos', 'pandemic', 'minneapolis', 'nojusticenopeace', 'jesus', 'rbnhole', 'afm', 'nonroot', 'dwmapidll', 'configxml', 'libpng', 'helpdesk', 'undisclosed', 'drag', 'aes', 'webmin', 'gnupg', 'philip', 'adsl', 'apex', 'responsive', 'depot', 'announcement', 'iii', 'dublin', 'loan', 'und', 'consultant', 'lucky', 'france', 'bbc', 'nowplaying', 'becoming', 'runs', 'dear', 'parents', 'kuwait', 'caught', 'cvss', 'memories', 'missouri', 'coronavirus', 'coop', 'metafile', 'xfa', 'categoryid', 'appscan', 'searchasp', 'profinet', 'rbac', 'httponly', 'vcs', 'idn', 'emptoris', 'kibana', 'mpls', 'gpg', 'evaluation', 'digit', 'vb', 'facility', 'slot', 'none', 'rogue', 'tee', 'rare', 'kid', 'finish', 'upper', 'useful', 'korean', 'dj', 'nist', 'exercise', 'funny', 'resort', 'favourite', 'queens', 'ding', 'happened', 'shared', 'congrats', 'oregon', 'england', 'privileges', 'loved', 'projects', 'cape', 'knots', 'invalidate', 'localhost', 'pkcs', 'mismatch', 'mxf', 'pia', 'bigiq', 'ocs', 'segv', 'rtp', 'confluence', 'hnap', 'zoneminder', 'keystroke', 'toolbar', 'ntfs', 'signon', 'ber', 'assembler', 'smaller', 'dating', 'ida', 'bomb', 'carrier', 'je', 'rep', 'att', 'exactly', 'jackson', 'mar', 'tesco', 'automotive', 'medicine', 'makeup', 'tls', 'ideas', 'reflashing', 'mainphp', 'fixpak', 'macromedia', 'webpage', 'cloudforms', 'etcpasswd', 'releasesandroid', 'epo', 'undefined', 'executables', 'paste', 'cleanup', 'logins', 'bsafe', 'floating', 'debugger', 'ram', 'centos', 'devops', 'crowd', 'collect', 'talent', 'concourse', 'roundup', 'gas', 'coordinator', 'rainbow', 'discount', 'offering', 'exam', 'ya', 'bear', 'executive', 'cooking', 'indiana', 'manchester', 'wit', 'fireeye', 'tells', 'encrypted', 'met', 'thankful', 'ladies', 'enjoyed', 'cotton', 'ssw', 'cvssavnaclprluinsucninah', 'sdmw', 'vcn', 'tamper', 'qcn', 'addqueryarg', 'businessobjects', 'ons', 'mailenable', 'ascii', 'assert', 'piwigo', 'usermode', 'revive', 'formula', 'expressway', 'clearing', 'shield', 'chips', 'dirty', 'brief', 'tap', 'rhsa', 'relax', 'leads', 'supported', 'happens', 'gave', 'paid', 'sms', 'helps', 'kali', 'homes', 'bought', 'views', 'orleans', 'barista', 'znpd', 'ldlibrarypath', 'msdos', 'micrologix', 'qcaa', 'openofficeorg', 'forumphp', 'wls', 'dcnm', 'userphp', 'logcat', 'zenworks', 'init', 'rhapsody', 'qnx', 'phorum', 'wonderware', 'openldap', 'pwd', 'modx', 'umotion', 'telemetry', 'optional', 'infusion', 'xxx', 'publishing', 'neighbor', 'plug', 'ide', 'bid', 'sha', 'tower', 'buffalo', 'highlight', 'ed', 'fan', 'alone', 'saying', 'xperia', 'adventure', 'sauce', 'bacon', 'everywhere', 'partners', 'knows', 'practices', 'learned', 'wood', 'throwback', 'guernsey', 'cscul', 'cscvh', 'mqtt', 'phpfusion', 'helix', 'dtd', 'presume', 'passphrase', 'multipart', 'manner', 'webrtc', 'jb', 'almond', 'imaging', 'adversary', 'heal', 'factor', 'unlimited', 'band', 'hybrid', 'reminder', 'english', 'ab', 'rat', 'heading', 'painting', 'ten', 'whatever', 'greatest', 'bigger', 'shirt', 'scams', 'trumps', 'professionals', 'according', 'aint', 'winter', 'largest', 'classes', 'detroit', 'licensed', 'xstore', 'do', 'brightstor', 'unixware', 'dn', 'cmd', 'psd', 'chroot', 'overrun', 'updater', 'cifs', 'uploader', 'graphical', 'confuse', 'vtiger', 'unserialize', 'dh', 'websense', 'mz', 'xa', 'representation', 'smh', 'evolve', 'flooding', 'except', 'coat', 'belong', 'snap', 'jail', 'crystal', 'newly', 'swift', 'disney', 'dropbox', 'gap', 'apparently', 'commercial', 'jan', 'attention', 'advice', 'yard', 'economic', 'strawberry', 'mexico', 'coach', 'ransom', 'antonio', 'giant', 'terrorism', 'pos', 'introducing', 'addresses', 'experienced', 'joy', 'ashley', 'intelligentexploitcomviewdetailsh', 'tmlid', 'platforms', 'streets', 'jacksonville', 'nnw', 'cscva', 'imail', 'cfnetwork', 'workbench', 'dwg', 'smartcloud', 'ltm', 'sugarcrm', 'adserver', 'cancel', 'pod', 'nasm', 'confirmation', 'generic', 'exim', 'tm', 'gm', 'anchor', 'cam', 'visitor', 'visibility', 'currency', 'laboratory', 'cna', 'respect', 'turning', 'cellular', 'annual', 'tom', 'solid', 'beef', 'comments', 'strategies', 'agencies', 'labs', 'seconds', 'thursday', 'faith', 'gardens', 'reposted', 'distancing', 'broadway', 'irving', 'aam', 'clearquest', 'memberphp', 'postnuke', 'numeric', 'silverstripe', 'unchecked', 'trustzone', 'limitation', 'keystone', 'sg', 'prestashop', 'circumvent', 'tlwrn', 'networker', 'indexing', 'zend', 'toplevel', 'ng', 'folsom', 'hence', 'dependent', 'resume', 'dvd', 'vanilla', 'ag', 'barracuda', 'acquisition', 'essex', 'rte', 'microsofts', 'christian', 'deck', 'netflix', 'paris', 'worry', 'fishing', 'automated', 'porn', 'requests', 'australian', 'americans', 'def', 'commands', 'talks', 'drones', 'pork', 'wanna', 'mill', 'stigma', 'fresenius', 'referrer', 'icewarp', 'phpsessid', 'powerdns', 'calendarphp', 'alstrasoft', 'gid', 'coppermine', 'expiration', 'xf', 'uxss', 'ld', 'ilo', 'pcf', 'systemd', 'ceph', 'absence', 'roundcube', 'ngfw', 'rsync', 'podofo', 'dl', 'applicable', 'temporarily', 'leap', 'dual', 'draft', 'mint', 'bm', 'bc', 'thomas', 'evil', 'highway', 'ese', 'expected', 'managed', 'followers', 'denver', 'fails', 'begins', 'ics', 'changed', 'odisseus', 'trees', 'manhattan', 'crosssitescripting', 'sinumerik', 'cscup', 'whitespace', 'cscuo', 'pageid', 'malps', 'xfs', 'uname', 'mmap', 'keyview', 'firstname', 'symphony', 'jetty', 'esm', 'homograph', 'belkin', 'autocad', 'mailman', 'mantis', 'markdown', 'webkitgtk', 'animation', 'cprsr', 'freeware', 'conducting', 'commander', 'lightweight', 'avg', 'rack', 'sy', 'influence', 'webcam', 'usually', 'vt', 'gate', 'eagle', 'adult', 'kindle', 'handson', 'judge', 'century', 'wow', 'neighborhood', 'oak', 'surprise', 'rice', 'wars', 'allowing', 'charges', 'alabama', 'italian', 'dss', 'sitting', 'jordan', 'rainy', 'healthwelfare', 'dml', 'certify', 'independently', 'querystring', 'subdirectory', 'altiris', 'forumid', 'additionally', 'unpublished', 'coderspngc', 'lastname', 'shortcut', 'dma', 'hyperlink', 'limesurvey', 'resolver', 'pollution', 'secondary', 'ontap', 'rewrite', 'res', 'freeradius', 'elasticsearch', 'complexity', 'ignite', 'ni', 'dna', 'extremely', 'packaging', 'ltd', 'elite', 'apsb', 'holding', 'ba', 'battery', 'resident', 'detecting', 'equipment', 'vacation', 'prayer', 'rose', 'cash', 'yellow', 'selfie', 'portrait', 'outbreak', 'asia', 'eastern', 'officially', 'pcs', 'standing', 'gartner', 'https', 'killed', 'linked', 'hundreds', 'dedicated', 'controls', 'malwaresecuritynews', 'cloudsecuritynews', 'issued', 'inspired', 'peerlyst', 'pics', 'mountains', 'graduation', 'cancer', 'pieces', 'yummy', 'meal', 'loaf', 'ptrace', 'headerphp', 'adc', 'hlos', 't', 'commentsphp', 'xmlhttprequest', 'tid', 'sppat', 'nondefault', 'lockout', 'blob', 'phar', 'smf', 'partially', 'vlan', 'jaspersoft', 'autotrace', 'xps', 'symfony', 'sftp', 'pict', 'argue', 'ref', 'sameorigin', 'smuggling', 'adb', 'federation', 'mercurial', 'thinkpad', 'winrar', 'rm', 'torrent', 'basis', 'compare', 'indoor', 'alienvault', 'lie', 'advertise', 'spotlight', 'fuel', 'proof', 'tablet', 'entertainment', 'distance', 'ff', 'malwarebytes', 'zeus', 'exclusive', 'fly', 'fantastic', 'tweet', 'steve', 'hanging', 'papers', 'minnesota', 'diy', 'microsofttechnet', 'lollydaskal', 'cheers', 'shares', 'iphones', 'patched', 'yearold', 'becomes', 'trails', 'sister', 'relaxing', 'connecticut', 'babies', 'at', 'uploadphp', 'charset', 'wnrpv', 'exv', 'etrust', 'csctq', 'woltlab', 'newsid', 'sinvr', 'hostnames']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[638, 617, 1367, 514, 378, 718, 401, 3753], [1604, 968, 1433, 3720, 154, 36, 702, 2338], [1447, 338, 239, 117, 239, 154, 1562, 330, 316, 1447, 117], [479, 369, 3862, 2178, 2762, 2732, 2718, 1042, 465], [677, 625, 3556, 677, 3141, 4878, 210, 3140, 2907], [], [45, 3992, 4898, 746], [678, 762, 850, 104, 790, 134, 142, 2487, 134, 4102], [453, 827, 1924], [1603]]\n"
     ]
    }
   ],
   "source": [
    "# USE THE TRANSFORMER WITHOUT PIPELINE\n",
    "text_sequence = TextToSequence(w1 = word_counts_1.value, w2 = word_counts_2.value)\n",
    "df_example = text_sequence.transform(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87d5b9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49878"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a2dd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d203266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0c2a566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134615"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counts_1.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "31b4343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710505"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counts_2.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ac8a684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|feature1                                                                                                                                                                                                                                                                                                                          |feature2                                                                                                                                                                                                                                                                                                                    |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[678, 1012, 2927, 1155, 3615, 52, 142, 3269, 693, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]|[2144, 3142, 1391, 837, 425, 2549, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]|\n",
      "|[313, 59, 316, 2965, 4898, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]           |[45, 1319, 1065, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]         |\n",
      "|[107, 3014, 3387, 11, 74, 3391, 353, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]       |[4169, 1626, 517, 2532, 2076, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  |\n",
      "|[1662, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                   |[523, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]              |\n",
      "|[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                      |[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_example.select('feature1','feature2').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "224cf27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99756"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e18ffd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3a09c4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- pos_t: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- feature1: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- feature2: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_example.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff304583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|_c0  |text                                                                                                         |label|pos_t                                                                                                                      |filtered_words                                                                                                |feature1                                                                                                                                                                                                                                                                                                           |feature2                                                                                                                                                                                                                                                                                                              |\n",
      "+-----+-------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|20364|siliconangle man pleads guilty to hacking gmail  apple mail accounts and obtaining xratedpics of cel  iabfef |0    |[siliconangle, man, pleads, guilty, to, hacking, gmail, apple, mail, accounts, and, obtaining, xratedpics, of, cel, iabfef]|[siliconangle, man, pleads, guilty, hacking, gmail, apple, mail, accounts, obtaining, xratedpics, cel, iabfef]|[1864, 127, 476, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]|[57, 3205, 1216, 1586, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]|\n",
      "+-----+-------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_example.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b81c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc64a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트를 벡터화하는 1번째 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b421c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "TEMPERATURE_COUNT = 100\n",
    "assembler_exploded = VectorAssembler(\n",
    "    inputCols=[\"feature1[{}]\".format(i) for i in range(TEMPERATURE_COUNT)], \n",
    "    outputCol=\"f1_vector\"\n",
    ")\n",
    "df_exploded = df_example.select(\n",
    "    df_example[\"label\"], \n",
    "    *[df_example[\"feature1\"][i] for i in range(TEMPERATURE_COUNT)]\n",
    ")\n",
    "converted_df = assembler_exploded.transform(df_exploded)\n",
    "final_df = converted_df.select(\"f1_vector\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "934e236e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- feature1[0]: long (nullable = true)\n",
      " |-- feature1[1]: long (nullable = true)\n",
      " |-- feature1[2]: long (nullable = true)\n",
      " |-- feature1[3]: long (nullable = true)\n",
      " |-- feature1[4]: long (nullable = true)\n",
      " |-- feature1[5]: long (nullable = true)\n",
      " |-- feature1[6]: long (nullable = true)\n",
      " |-- feature1[7]: long (nullable = true)\n",
      " |-- feature1[8]: long (nullable = true)\n",
      " |-- feature1[9]: long (nullable = true)\n",
      " |-- feature1[10]: long (nullable = true)\n",
      " |-- feature1[11]: long (nullable = true)\n",
      " |-- feature1[12]: long (nullable = true)\n",
      " |-- feature1[13]: long (nullable = true)\n",
      " |-- feature1[14]: long (nullable = true)\n",
      " |-- feature1[15]: long (nullable = true)\n",
      " |-- feature1[16]: long (nullable = true)\n",
      " |-- feature1[17]: long (nullable = true)\n",
      " |-- feature1[18]: long (nullable = true)\n",
      " |-- feature1[19]: long (nullable = true)\n",
      " |-- feature1[20]: long (nullable = true)\n",
      " |-- feature1[21]: long (nullable = true)\n",
      " |-- feature1[22]: long (nullable = true)\n",
      " |-- feature1[23]: long (nullable = true)\n",
      " |-- feature1[24]: long (nullable = true)\n",
      " |-- feature1[25]: long (nullable = true)\n",
      " |-- feature1[26]: long (nullable = true)\n",
      " |-- feature1[27]: long (nullable = true)\n",
      " |-- feature1[28]: long (nullable = true)\n",
      " |-- feature1[29]: long (nullable = true)\n",
      " |-- feature1[30]: long (nullable = true)\n",
      " |-- feature1[31]: long (nullable = true)\n",
      " |-- feature1[32]: long (nullable = true)\n",
      " |-- feature1[33]: long (nullable = true)\n",
      " |-- feature1[34]: long (nullable = true)\n",
      " |-- feature1[35]: long (nullable = true)\n",
      " |-- feature1[36]: long (nullable = true)\n",
      " |-- feature1[37]: long (nullable = true)\n",
      " |-- feature1[38]: long (nullable = true)\n",
      " |-- feature1[39]: long (nullable = true)\n",
      " |-- feature1[40]: long (nullable = true)\n",
      " |-- feature1[41]: long (nullable = true)\n",
      " |-- feature1[42]: long (nullable = true)\n",
      " |-- feature1[43]: long (nullable = true)\n",
      " |-- feature1[44]: long (nullable = true)\n",
      " |-- feature1[45]: long (nullable = true)\n",
      " |-- feature1[46]: long (nullable = true)\n",
      " |-- feature1[47]: long (nullable = true)\n",
      " |-- feature1[48]: long (nullable = true)\n",
      " |-- feature1[49]: long (nullable = true)\n",
      " |-- feature1[50]: long (nullable = true)\n",
      " |-- feature1[51]: long (nullable = true)\n",
      " |-- feature1[52]: long (nullable = true)\n",
      " |-- feature1[53]: long (nullable = true)\n",
      " |-- feature1[54]: long (nullable = true)\n",
      " |-- feature1[55]: long (nullable = true)\n",
      " |-- feature1[56]: long (nullable = true)\n",
      " |-- feature1[57]: long (nullable = true)\n",
      " |-- feature1[58]: long (nullable = true)\n",
      " |-- feature1[59]: long (nullable = true)\n",
      " |-- feature1[60]: long (nullable = true)\n",
      " |-- feature1[61]: long (nullable = true)\n",
      " |-- feature1[62]: long (nullable = true)\n",
      " |-- feature1[63]: long (nullable = true)\n",
      " |-- feature1[64]: long (nullable = true)\n",
      " |-- feature1[65]: long (nullable = true)\n",
      " |-- feature1[66]: long (nullable = true)\n",
      " |-- feature1[67]: long (nullable = true)\n",
      " |-- feature1[68]: long (nullable = true)\n",
      " |-- feature1[69]: long (nullable = true)\n",
      " |-- feature1[70]: long (nullable = true)\n",
      " |-- feature1[71]: long (nullable = true)\n",
      " |-- feature1[72]: long (nullable = true)\n",
      " |-- feature1[73]: long (nullable = true)\n",
      " |-- feature1[74]: long (nullable = true)\n",
      " |-- feature1[75]: long (nullable = true)\n",
      " |-- feature1[76]: long (nullable = true)\n",
      " |-- feature1[77]: long (nullable = true)\n",
      " |-- feature1[78]: long (nullable = true)\n",
      " |-- feature1[79]: long (nullable = true)\n",
      " |-- feature1[80]: long (nullable = true)\n",
      " |-- feature1[81]: long (nullable = true)\n",
      " |-- feature1[82]: long (nullable = true)\n",
      " |-- feature1[83]: long (nullable = true)\n",
      " |-- feature1[84]: long (nullable = true)\n",
      " |-- feature1[85]: long (nullable = true)\n",
      " |-- feature1[86]: long (nullable = true)\n",
      " |-- feature1[87]: long (nullable = true)\n",
      " |-- feature1[88]: long (nullable = true)\n",
      " |-- feature1[89]: long (nullable = true)\n",
      " |-- feature1[90]: long (nullable = true)\n",
      " |-- feature1[91]: long (nullable = true)\n",
      " |-- feature1[92]: long (nullable = true)\n",
      " |-- feature1[93]: long (nullable = true)\n",
      " |-- feature1[94]: long (nullable = true)\n",
      " |-- feature1[95]: long (nullable = true)\n",
      " |-- feature1[96]: long (nullable = true)\n",
      " |-- feature1[97]: long (nullable = true)\n",
      " |-- feature1[98]: long (nullable = true)\n",
      " |-- feature1[99]: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_exploded.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bf4c942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- feature1[0]: long (nullable = true)\n",
      " |-- feature1[1]: long (nullable = true)\n",
      " |-- feature1[2]: long (nullable = true)\n",
      " |-- feature1[3]: long (nullable = true)\n",
      " |-- feature1[4]: long (nullable = true)\n",
      " |-- feature1[5]: long (nullable = true)\n",
      " |-- feature1[6]: long (nullable = true)\n",
      " |-- feature1[7]: long (nullable = true)\n",
      " |-- feature1[8]: long (nullable = true)\n",
      " |-- feature1[9]: long (nullable = true)\n",
      " |-- feature1[10]: long (nullable = true)\n",
      " |-- feature1[11]: long (nullable = true)\n",
      " |-- feature1[12]: long (nullable = true)\n",
      " |-- feature1[13]: long (nullable = true)\n",
      " |-- feature1[14]: long (nullable = true)\n",
      " |-- feature1[15]: long (nullable = true)\n",
      " |-- feature1[16]: long (nullable = true)\n",
      " |-- feature1[17]: long (nullable = true)\n",
      " |-- feature1[18]: long (nullable = true)\n",
      " |-- feature1[19]: long (nullable = true)\n",
      " |-- feature1[20]: long (nullable = true)\n",
      " |-- feature1[21]: long (nullable = true)\n",
      " |-- feature1[22]: long (nullable = true)\n",
      " |-- feature1[23]: long (nullable = true)\n",
      " |-- feature1[24]: long (nullable = true)\n",
      " |-- feature1[25]: long (nullable = true)\n",
      " |-- feature1[26]: long (nullable = true)\n",
      " |-- feature1[27]: long (nullable = true)\n",
      " |-- feature1[28]: long (nullable = true)\n",
      " |-- feature1[29]: long (nullable = true)\n",
      " |-- feature1[30]: long (nullable = true)\n",
      " |-- feature1[31]: long (nullable = true)\n",
      " |-- feature1[32]: long (nullable = true)\n",
      " |-- feature1[33]: long (nullable = true)\n",
      " |-- feature1[34]: long (nullable = true)\n",
      " |-- feature1[35]: long (nullable = true)\n",
      " |-- feature1[36]: long (nullable = true)\n",
      " |-- feature1[37]: long (nullable = true)\n",
      " |-- feature1[38]: long (nullable = true)\n",
      " |-- feature1[39]: long (nullable = true)\n",
      " |-- feature1[40]: long (nullable = true)\n",
      " |-- feature1[41]: long (nullable = true)\n",
      " |-- feature1[42]: long (nullable = true)\n",
      " |-- feature1[43]: long (nullable = true)\n",
      " |-- feature1[44]: long (nullable = true)\n",
      " |-- feature1[45]: long (nullable = true)\n",
      " |-- feature1[46]: long (nullable = true)\n",
      " |-- feature1[47]: long (nullable = true)\n",
      " |-- feature1[48]: long (nullable = true)\n",
      " |-- feature1[49]: long (nullable = true)\n",
      " |-- feature1[50]: long (nullable = true)\n",
      " |-- feature1[51]: long (nullable = true)\n",
      " |-- feature1[52]: long (nullable = true)\n",
      " |-- feature1[53]: long (nullable = true)\n",
      " |-- feature1[54]: long (nullable = true)\n",
      " |-- feature1[55]: long (nullable = true)\n",
      " |-- feature1[56]: long (nullable = true)\n",
      " |-- feature1[57]: long (nullable = true)\n",
      " |-- feature1[58]: long (nullable = true)\n",
      " |-- feature1[59]: long (nullable = true)\n",
      " |-- feature1[60]: long (nullable = true)\n",
      " |-- feature1[61]: long (nullable = true)\n",
      " |-- feature1[62]: long (nullable = true)\n",
      " |-- feature1[63]: long (nullable = true)\n",
      " |-- feature1[64]: long (nullable = true)\n",
      " |-- feature1[65]: long (nullable = true)\n",
      " |-- feature1[66]: long (nullable = true)\n",
      " |-- feature1[67]: long (nullable = true)\n",
      " |-- feature1[68]: long (nullable = true)\n",
      " |-- feature1[69]: long (nullable = true)\n",
      " |-- feature1[70]: long (nullable = true)\n",
      " |-- feature1[71]: long (nullable = true)\n",
      " |-- feature1[72]: long (nullable = true)\n",
      " |-- feature1[73]: long (nullable = true)\n",
      " |-- feature1[74]: long (nullable = true)\n",
      " |-- feature1[75]: long (nullable = true)\n",
      " |-- feature1[76]: long (nullable = true)\n",
      " |-- feature1[77]: long (nullable = true)\n",
      " |-- feature1[78]: long (nullable = true)\n",
      " |-- feature1[79]: long (nullable = true)\n",
      " |-- feature1[80]: long (nullable = true)\n",
      " |-- feature1[81]: long (nullable = true)\n",
      " |-- feature1[82]: long (nullable = true)\n",
      " |-- feature1[83]: long (nullable = true)\n",
      " |-- feature1[84]: long (nullable = true)\n",
      " |-- feature1[85]: long (nullable = true)\n",
      " |-- feature1[86]: long (nullable = true)\n",
      " |-- feature1[87]: long (nullable = true)\n",
      " |-- feature1[88]: long (nullable = true)\n",
      " |-- feature1[89]: long (nullable = true)\n",
      " |-- feature1[90]: long (nullable = true)\n",
      " |-- feature1[91]: long (nullable = true)\n",
      " |-- feature1[92]: long (nullable = true)\n",
      " |-- feature1[93]: long (nullable = true)\n",
      " |-- feature1[94]: long (nullable = true)\n",
      " |-- feature1[95]: long (nullable = true)\n",
      " |-- feature1[96]: long (nullable = true)\n",
      " |-- feature1[97]: long (nullable = true)\n",
      " |-- feature1[98]: long (nullable = true)\n",
      " |-- feature1[99]: long (nullable = true)\n",
      " |-- f1_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converted_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fde469b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- f1_vector: vector (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9f5c3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+-----+\n",
      "|f1_vector                                                                     |label|\n",
      "+------------------------------------------------------------------------------+-----+\n",
      "|(100,[0,1,2,3,4,5,6,7],[4303.0,866.0,1635.0,2954.0,1705.0,96.0,1471.0,2960.0])|1    |\n",
      "|(100,[0,1,2,3],[1635.0,255.0,4643.0,1115.0])                                  |0    |\n",
      "|(100,[0,1,2,3,4,5],[2242.0,2226.0,1136.0,2802.0,324.0,2448.0])                |0    |\n",
      "|(100,[0,1,2],[866.0,174.0,4915.0])                                            |1    |\n",
      "|(100,[0],[1849.0])                                                            |1    |\n",
      "+------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트를 벡터화하는 두번째 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5cab200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "df_with_vectors = df_example.select(\n",
    "    df_example[\"label\"], \n",
    "    list_to_vector_udf(df_example[\"feature1\"]).alias(\"feature1\"),\n",
    "    list_to_vector_udf(df_example[\"feature2\"]).alias(\"feature2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ba2e4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_vectors.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "642f69a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- feature1: vector (nullable = true)\n",
      " |-- feature2: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_vectors.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a8506af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>feature1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[4303.0, 866.0, 1635.0, 2954.0, 1705.0, 96.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[1635.0, 255.0, 4643.0, 1115.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[2242.0, 2226.0, 1136.0, 2802.0, 324.0, 2448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[866.0, 174.0, 4915.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[1849.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           feature1\n",
       "0     1  [4303.0, 866.0, 1635.0, 2954.0, 1705.0, 96.0, ...\n",
       "1     0  [1635.0, 255.0, 4643.0, 1115.0, 0.0, 0.0, 0.0,...\n",
       "2     0  [2242.0, 2226.0, 1136.0, 2802.0, 324.0, 2448.0...\n",
       "3     1  [866.0, 174.0, 4915.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "4     1  [1849.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_vectors.select('label', 'feature1').limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd9b1f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# va = VectorAssembler(inputCols=['feature1'], outputCol='features')\n",
    "# d1 = va.transform(df_with_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6a4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f906be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_str_index = StringIndexer(inputCol='label', outputCol='label_index')\n",
    "d4 = label_str_index.fit(df_with_vectors).transform(df_with_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d01e825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- feature1: vector (nullable = true)\n",
      " |-- feature2: vector (nullable = true)\n",
      " |-- label_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6816f597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "067a23a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_index</th>\n",
       "      <th>feature1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[805.0, 2640.0, 51.0, 811.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[285.0, 60.0, 1614.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[111.0, 3829.0, 11.0, 76.0, 405.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[1524.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_index                                           feature1\n",
       "0          0.0  [805.0, 2640.0, 51.0, 811.0, 0.0, 0.0, 0.0, 0....\n",
       "1          0.0  [285.0, 60.0, 1614.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "2          0.0  [111.0, 3829.0, 11.0, 76.0, 405.0, 0.0, 0.0, 0...\n",
       "3          0.0  [1524.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....\n",
       "4          0.0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4.select('label_index', 'feature1').limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ad18658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49878"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "935e34f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|feature1                                                                                                                                                                                                                                                                                                                                                                                                                |feature2                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[1864.0,127.0,476.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]|[57.0,3205.0,1216.0,1586.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]|\n",
      "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_vectors.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797bd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THE TRANSFORMER WITH PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34172737",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sequence = TextToSequence(w1 = word_counts_1, w2 = word_counts_2)\n",
    "#df_example = text_sequence.transform(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94836f2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|            features|_c0|                text|label|               pos_t|      filtered_words|            feature1|            feature2|\n",
      "+--------------------+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|[[2871, 52, 614, ...|  0|threatmeter hacke...|    0|[threatmeter, hac...|[threatmeter, hac...|[2871, 52, 614, 4...|[1693, 1001, 2716...|\n",
      "|[[504, 59, 1094, ...|  1|first android mal...|    0|[first, android, ...|[first, android, ...|[504, 59, 1094, 0...|[46, 3724, 0, 0, ...|\n",
      "|[[105, 4698, 11, ...|  2|adobe fixes six c...|    0|[adobe, fixes, si...|[adobe, fixes, si...|[105, 4698, 11, 7...|[1578, 667, 2657,...|\n",
      "|[[1507, 0, 0, 0, ...|  3| scienceporn  in ...|    0|[scienceporn, in,...|[scienceporn, vac...|[1507, 0, 0, 0, 0...|[507, 0, 0, 0, 0,...|\n",
      "|[[0, 0, 0, 0, 0, ...|  4|riskware hmoyfzb ...|    0|[riskware, hmoyfz...|[riskware, hmoyfz...|[0, 0, 0, 0, 0, 0...|[0, 0, 0, 0, 0, 0...|\n",
      "+--------------------+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "text_sequence = TextToSequence(w1 = word_counts_1, w2 = word_counts_2)\n",
    "med_model = Pipeline(stages=[stage_1, stage_2, text_sequence]).fit(csi_pos_neg)\n",
    "bucketedData = med_model.transform(csi_pos_neg)\n",
    "bucketedData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee661aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform_fin = bucketedData.orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f05dccdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transform_fin.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b23aeda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transform_fin = df_transform_fin.repartition(10000)\n",
    "df_transform_fin.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facaaf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = df_transform_fin.select(\"label\").distinct().count()\n",
    "nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301647f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bce4b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classes = d4.select(\"label\").distinct().count()\n",
    "nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8d073c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199512"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cf5d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "sc = spark._jsc.sc() \n",
    "n_workers =  len([executor.host() for executor in sc.statusTracker().getExecutorInfos() ]) -1\n",
    "\n",
    "print(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eb7ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from tensorflow.python.keras.layers import Conv1D, Flatten, GlobalMaxPooling1D, Dropout, MaxPooling1D, Activation, Bidirectional, Conv2D, GlobalMaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c67e6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = 5001\n",
    "neg_vocab_sizes = 5001\n",
    "embedding_vector_length = 100\n",
    "hidden_dims = 250\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "029cc054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 100)          500100    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               234496    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 735,110\n",
      "Trainable params: 735,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_sizes, embedding_vector_length, input_length=max_length))\n",
    "\n",
    "#어휘 크기(최대 정수 인덱스+1, 고밀도 임베딩의 치수, 입력 시퀀스의 길이\n",
    "\n",
    "# 모델은 크기의 정수 행렬 (배치,\n",
    "# input_length) 및 입력에서 가장 큰 정수 (즉, 단어 인덱스)\n",
    "#은 999 (어휘 크기)보다 크지 않아야합니다.\n",
    "# 이제 model.output_shape는 (None, 10, 64)이고, 여기서`None`은 배치입니다.\n",
    "# dimension.\n",
    "\n",
    "\n",
    "# model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# #체크포인트 생성?!\n",
    "# # checkpoint_filepath = '/root/spark/baseline/'\n",
    "# fname = \"checkpoint-{epoch:02d}-{val_loss:.2f}\"\n",
    "# checkpoint = ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\",\n",
    "#     save_best_only=True, verbose=1)\n",
    "# callbacks = [checkpoint]\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b90ce541",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 100, 100)     500100      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 100, 100)     500100      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 256)          234496      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 256)          234496      embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            4104        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            18          dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,473,314\n",
      "Trainable params: 1,473,314\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CSI positive Embedding model\n",
    "inputA = Input(shape=(100,))\n",
    "x = Embedding(vocab_sizes, embedding_vector_length, input_length=max_length)(inputA)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x = MaxPool1D(strides=1, padding='valid')(x)\n",
    "x = Bidirectional(LSTM(128))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# CSI negative Embedding model\n",
    "inputC = Input(shape=(100,))\n",
    "k = Embedding(neg_vocab_sizes, embedding_vector_length, input_length=max_length)(inputC)\n",
    "# k = Conv1D(128, 5, activation='relu')(k)\n",
    "# k = MaxPool1D(strides=1, padding='valid')(k)\n",
    "k = Bidirectional(LSTM(128))(k)\n",
    "k = Dropout(0.2)(k)\n",
    "k = Activation('relu')(k)\n",
    "k = Model(inputs=inputC, outputs=k)\n",
    "\n",
    "combined = concatenate([x.output, k.output], axis=1)\n",
    "# z = Flatten()(combined)\n",
    "z = Dense(8, activation='relu')(combined)\n",
    "z = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, k.input], outputs=z)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e4180fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer_conf = optimizers.Adam(lr=0.01)\n",
    "opt_conf = optimizers.serialize(optimizer_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4cca512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElephasEstimator_bb12150c039d"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from elephas import spark_model, ml_model\n",
    "from elephas.ml_model import ElephasEstimator\n",
    "\n",
    "estimator = ElephasEstimator()\n",
    "estimator.setFeaturesCol(\"feature1\")\n",
    "estimator.setLabelCol(\"label_index\")\n",
    "estimator.set_keras_model_config(model.to_json())\n",
    "estimator.set_categorical_labels(True) # dense 1이면 False로 설정해야함\n",
    "estimator.set_nb_classes(nb_classes)\n",
    "estimator.set_num_workers(1)\n",
    "estimator.set_epochs(10)\n",
    "estimator.set_batch_size(32)\n",
    "estimator.set_verbosity(1)\n",
    "estimator.set_validation_split(0.10)\n",
    "estimator.set_optimizer_config(opt_conf)\n",
    "estimator.set_mode(\"synchronous\")\n",
    "estimator.set_loss(\"binary_crossentropy\")\n",
    "estimator.set_metrics(['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10c53a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_pipeline = Pipeline(stages=[estimator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a304597c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Fit model\n",
      ">>> Synchronous training complete.\n"
     ]
    }
   ],
   "source": [
    "my_dl = dl_pipeline.fit(d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "76db8406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_transform_fin.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "42e65586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transform_fin.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a403cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import Row\n",
    "# from pyspark.ml.linalg import Vectors\n",
    "# city_rdd = df_transform_fin.rdd.map(lambda row:row[3])\n",
    "# temp_rdd = df_transform_fin.rdd.map(lambda row:row[0])\n",
    "# new_df = city_rdd.zip(temp_rdd.map(lambda x:Vectors.dense(x))).toDF(schema=['label','features'])\n",
    "\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8a6ca535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2e27610c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_dl.write().overwrite().save('hdfs:///user/root/model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24f64910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2bd3d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_train = my_dl.transform(d1)\n",
    "pred_test = my_dl.transform(d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "216a9b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-----------+--------------------+\n",
      "|label|            feature1|            feature2|label_index|          prediction|\n",
      "+-----+--------------------+--------------------+-----------+--------------------+\n",
      "|    0|[638.0,617.0,1367...|[3741.0,3625.0,25...|        0.0|[0.99938523769378...|\n",
      "|    0|[1604.0,968.0,143...|[1282.0,916.0,121...|        0.0|[0.99788296222686...|\n",
      "|    0|[1447.0,338.0,239...|[416.0,837.0,416....|        0.0|[0.99794328212738...|\n",
      "|    0|[479.0,369.0,3862...|[6.0,29.0,1511.0,...|        0.0|[0.99982774257659...|\n",
      "|    0|[677.0,625.0,3556...|[4713.0,2203.0,49...|        0.0|[0.99977290630340...|\n",
      "+-----+--------------------+--------------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "461c1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "list_to_double = udf(lambda l: l[0], DoubleType())\n",
    "pred_test = pred_test.select(\n",
    "    pred_test[\"label_index\"], \n",
    "    list_to_double(pred_test[\"prediction\"]).alias(\"prediction2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aab450d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label_index: double (nullable = false)\n",
      " |-- prediction2: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "147f778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|label_index|prediction2       |\n",
      "+-----------+------------------+\n",
      "|0.0        |0.9993852376937866|\n",
      "|0.0        |0.9978829622268677|\n",
      "|0.0        |0.9979432821273804|\n",
      "|0.0        |0.9998277425765991|\n",
      "|0.0        |0.9997729063034058|\n",
      "+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c1f0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "list_to_vector_udf = udf(lambda l:1.0 if l<0.5 else 0.0 , DoubleType())\n",
    "pred_test = pred_test.select(\n",
    "    pred_test[\"label_index\"], \n",
    "    list_to_vector_udf(pred_test[\"prediction2\"]).alias(\"rawPrediction\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c6cf9090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|label_index|rawPrediction|\n",
      "+-----------+-------------+\n",
      "|1.0        |1.0          |\n",
      "|1.0        |1.0          |\n",
      "|1.0        |1.0          |\n",
      "|1.0        |1.0          |\n",
      "|1.0        |1.0          |\n",
      "|1.0        |1.0          |\n",
      "|1.0        |1.0          |\n",
      "|1.0        |0.0          |\n",
      "|1.0        |1.0          |\n",
      "|1.0        |1.0          |\n",
      "+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b6c489b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|rawPrediction|count|\n",
      "+-------------+-----+\n",
      "|          1.0| 6939|\n",
      "|          0.0|42939|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test.groupBy('rawPrediction').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b96960e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|label_index|rawPrediction|\n",
      "+-----------+-------------+\n",
      "|          0|            0|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "pred_test.select([count(when(isnan(c), c)).alias(c) for c in pred_test.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9a4cc",
   "metadata": {},
   "source": [
    "#### ROC AUC구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "667cfb3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC Curve: 0.1467\n",
      "Area under PR Curve: 0.3095\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Let's use the run-of-the-mill evaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label_index')\n",
    "\n",
    "# We have only two choices: area under ROC and PR curves :-(\n",
    "auroc = evaluator.evaluate(pred_test, {evaluator.metricName: \"areaUnderROC\"})\n",
    "auprc = evaluator.evaluate(pred_test, {evaluator.metricName: \"areaUnderPR\"})\n",
    "print(\"Area under ROC Curve: {:.4f}\".format(auroc))\n",
    "print(\"Area under PR Curve: {:.4f}\".format(auprc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f3a10",
   "metadata": {},
   "source": [
    "#### Precision, Recall 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad61d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\", predictionCol=\"rawPrediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f66398cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5523076306187097\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(pred_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "40eb6243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\", predictionCol=\"rawPrediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea612e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9184711292471107\n"
     ]
    }
   ],
   "source": [
    "f1 = evaluator.evaluate(pred_test)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8e5515cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\", predictionCol=\"rawPrediction\", metricName=\"weightedPrecision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "92f4629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919118309422521\n"
     ]
    }
   ],
   "source": [
    "weightedPrecision = evaluator.evaluate(pred_test)\n",
    "print(weightedPrecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d950572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_index\", predictionCol=\"rawPrediction\", metricName=\"weightedRecall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8c715f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185011427884038\n"
     ]
    }
   ],
   "source": [
    "weightedRecall = evaluator.evaluate(pred_test)\n",
    "print(weightedRecall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dc559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b8bf8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pnl_train = pred_train.select('label_index', \"prediction2\")\n",
    "pnl_test = pred_test.select('label_index', \"rawPrediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1a68ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_and_label_train = pnl_train.rdd.map(lambda row: (row['label_index'], row['prediction2']))\n",
    "pred_and_label_test = pnl_test.rdd.map(lambda row: (row['label_index'],row['rawPrediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0854cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_train = MulticlassMetrics(pred_and_label_train)\n",
    "metrics_test = MulticlassMetrics(pred_and_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4eb766c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: 0.9539476322226232 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-4e083d23747f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# display(pnl_train.crosstab('label_index', 'prediction').toPandas())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTest Data Accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(\"Test Data Confusion Matrix\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# display(pnl_test.crosstab(\"label_index\", \"prediction\").toPandas())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mround\u001b[0;34m(col, scale)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \"\"\"\n\u001b[1;32m    601\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;34m\"{0} of type {1}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;34m\"For column literals, use 'lit', 'array', 'struct' or 'create_map' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \"function.\".format(col, type(col)))\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mjcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid argument, not a string or column: 0.9539476322226232 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "# print(\"Training Data Accuracy: {}\".format(round(metrics_train.precision(), 4)))\n",
    "# print(\"Training Data Confusion Matrix\")\n",
    "# display(pnl_train.crosstab('label_index', 'prediction').toPandas())\n",
    "\n",
    "print(\"\\nTest Data Accuracy: {}\".format(metrics_test.precision()))\n",
    "# print(\"Test Data Confusion Matrix\")\n",
    "# display(pnl_test.crosstab(\"label_index\", \"prediction\").toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "221f104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9539476322226232"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_test.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d98cdb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105727"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_1.value.get('allow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc39cd2",
   "metadata": {},
   "source": [
    "#### Broadcast 변수 update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39234fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcastWrapper(object):\n",
    "    def __init__(self, data, token_list):\n",
    "        self.broadcast_var = data\n",
    "#         self.last_updated_time = datetime.now()\n",
    "        self.token_list = token_list\n",
    "        \n",
    "#     def is_should_be_updated(self, data):\n",
    "#         cur_time = datetime.now()\n",
    "#         diff_sec = (cur_time - self.last_updated_time).total_seconds()\n",
    "#         return self.broadcast_var is None or diff_sec> 1\n",
    "    \n",
    "    def update_and_get_data(self, spark):\n",
    "        a = self.broadcast_var.value\n",
    "        self.broadcast_var.unpersist()\n",
    "        for i in self.token_list:\n",
    "            a[i] += 1\n",
    "        new_data = a\n",
    "        \n",
    "        self.broadcast_var = spark.broadcast(new_data)\n",
    "#         self.last_updated_time = datetime.now()\n",
    "    \n",
    "        return self.broadcast_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af3404dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "aa = sc.broadcast({'a':1, 'b':2, 'c':3})\n",
    "broadcast_wrapper = BroadcastWrapper(aa,['a', 'c'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "511c3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = broadcast_wrapper.update_and_get_data(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52113319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 2, 'c': 4}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc3e4dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 2, 'c': 4}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast_wrapper.broadcast_var.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7351f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = spark.sparkContext._conf.setAll([(\"spark.streaming.concurrentJobs\", \"2\")])\n",
    "\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"TwitterClassification\") \\\n",
    "            .config(conf=conf) \\\n",
    "            .config(\"spark.streaming.concurrentJobs\", \"2\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95af0e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.history.fs.logDirectory', 'file:///root/spark/eventLog'),\n",
       " ('spark.driver.host', 'kafka1'),\n",
       " ('spark.network.timeout', '3600s'),\n",
       " ('spark.app.name', 'TwitterClassification'),\n",
       " ('spark.executor.memory', '6g'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.streaming.concurrentJobs', '2'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.port', '38277'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.id', 'local-1632550969090'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.default.parallelism', '20'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.eventLog.dir', 'file:///root/spark/eventLog'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.kryoserializer.buffer.max', '2047'),\n",
       " ('spark.master', 'local[9]')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65eee042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://kafka1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[9]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f738e0126a0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba743904",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_pipeline = Pipeline(stages=[estimator])\n",
    "model = dl_pipeline.fit(df.map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"TwitterClassification\") \\\n",
    "            .config(\"spark.streaming.concurrentJobs\", \"2\")\n",
    "            .getOrCreate()\n",
    "\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    \n",
    "    kafka_df = spark.readStream.format(\"kafka\").option(\"partition.assignment.strategy\",\"range\").option(\"kafka.bootstrap.servers\", \"kafka1:9092,kafka2:9092,kafka3:9093\").option(\"subscribe\", \"test1,test2,test3\").option(\"startingOffsets\", \"latest\").load()\n",
    "    kafka_df.printSchema()\n",
    "    kafka_df1 = kafka_df.selectExpr(\"CAST(value AS STRING)\", \"timestamp\")\n",
    "    \n",
    "    transaction_detail_schema = StructType() \\\n",
    "            .add(\"id\", StringType()) \\\n",
    "            .add(\"text\", StringType()) \\\n",
    "            .add(\"created_at\", StringType())\n",
    "    \n",
    "    kafka_df2 = kafka_df1 \\\n",
    "            .select(from_json(col(\"value\"), transaction_detail_schema).alias(\"transaction_detail\"), \"timestamp\")\n",
    "\n",
    "    kafka_df3 = kafka_df2.select(\"transaction_detail.*\", \"timestamp\")\n",
    " \n",
    "    udf_blob = udf(apply_blob, StringType())\n",
    "    \n",
    "    udf_nlkt = udf(nlkt_analysis, StringType())\n",
    "    \n",
    "    new_df = kafka_df3.withColumn(\"status\", udf_nlkt(\"text\"))\n",
    "    new_df = new_df.drop(\"text\")\n",
    "\n",
    "    def write_mongo_row(df, epoch_id):\n",
    "        mongoURL = \"mongodb://117.17.189.6:27017/tweet.kafka_tweet\"\n",
    "        df.write.format(\"com.mongodb.spark.sql.DefaultSource\").mode(\"append\").option(\"uri\", mongoURL).save()\n",
    "        df.show()\n",
    "        pass\n",
    "    query = new_df.writeStream.trigger(processingTime='1 seconds').foreachBatch(write_mongo_row).start() \n",
    "    print('---------------------------------------------')\n",
    "    query.awaitTermination()\n",
    "\n",
    "    spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69d3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed22238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f8189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844409f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a33b925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddb564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e9bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4a715863",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[80, 0]</td>\n",
       "      <td>[90, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[70, 13]</td>\n",
       "      <td>[80, 34]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         aa        nn\n",
       "0   [80, 0]   [90, 1]\n",
       "1  [70, 13]  [80, 34]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1f = pd.DataFrame([[[80, 0],[90, 1]],[[70,13],[80,34]]],columns=['aa','nn'])\n",
    "d1f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4d943761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([80, 0]), list([70, 13])], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1f['aa'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "679e1052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([80, 0]) list([90, 1])]\n",
      "[list([70, 13]) list([80, 34])]\n"
     ]
    }
   ],
   "source": [
    "cols = ['aa','nn']\n",
    "def make_original(x) :\n",
    "    print(x.values)\n",
    "    tmp = []\n",
    "    tmp.append(x.values)\n",
    "    return tmp\n",
    "d1f.insert(0, 'eee', d1f[cols].apply(lambda row: make_original(row), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "005fc1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list([80, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9cac3dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "606f50f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a5b6de25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [[[80, 0], [90, 1]]]\n",
       "1    [[[70, 13], [80, 34]]]\n",
       "Name: eee, dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1f['eee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b95aa2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80, 0]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1f['eee'].iloc[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4e7291d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eee</th>\n",
       "      <th>aa</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[80, 0], [90, 1]]]</td>\n",
       "      <td>[80, 0]</td>\n",
       "      <td>[90, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[70, 13], [80, 34]]]</td>\n",
       "      <td>[70, 13]</td>\n",
       "      <td>[80, 34]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eee        aa        nn\n",
       "0    [[[80, 0], [90, 1]]]   [80, 0]   [90, 1]\n",
       "1  [[[70, 13], [80, 34]]]  [70, 13]  [80, 34]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a511dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f2456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427f144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25546912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1124320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ EX ############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6a71afc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------+\n",
      "|_1 |_2                                 |\n",
      "+---+-----------------------------------+\n",
      "|0.0|Hi I heard about Spark             |\n",
      "|0.0|I wish Java could use case classes |\n",
      "|1.0|Logistic regression models are neat|\n",
      "+---+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import arrays_zip\n",
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, \"Hi I heard about Spark\"),\n",
    "    (0.0, \"I wish Java could use case classes\"),\n",
    "    (1.0, \"Logistic regression models are neat\")\n",
    "]\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "370dcbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------+\n",
      "|data                                                                                                                  |\n",
      "+----------------------------------------------------------------------------------------------------------------------+\n",
      "|[[0.0, Hi I heard about Spark], [0.0, I wish Java could use case classes], [1.0, Logistic regression models are neat]]|\n",
      "+----------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_data = ['a' ,'b', 'c']\n",
    "\n",
    "df = df.select(collect_list(struct(F.col(\"*\"))).alias(\"data\"))\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8eb07b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|data                                                                                                                  |list     |\n",
      "+----------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|[[0.0, I wish Java could use case classes], [1.0, Logistic regression models are neat], [0.0, Hi I heard about Spark]]|[a, b, c]|\n",
      "+----------------------------------------------------------------------------------------------------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"list\",F.array([F.lit(i) for i in list_data]))\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bdefd577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------+\n",
      "|full_data                                      |\n",
      "+-----------------------------------------------+\n",
      "|[[0.0, I wish Java could use case classes], a] |\n",
      "|[[1.0, Logistic regression models are neat], b]|\n",
      "|[[0.0, Hi I heard about Spark], c]             |\n",
      "+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(F.explode(F.arrays_zip(F.col(\"data\"),F.col(\"list\"))).alias(\"full_data\"))\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1fed24d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------+----+\n",
      "|_1 |_2                                 |col3|\n",
      "+---+-----------------------------------+----+\n",
      "|0.0|Hi I heard about Spark             |a   |\n",
      "|0.0|I wish Java could use case classes |b   |\n",
      "|1.0|Logistic regression models are neat|c   |\n",
      "+---+-----------------------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(F.col(\"full_data.data.*\"),F.col(\"full_data.list\").alias(\"col3\"))\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### 해당 내용 list에도 적용가능한지 확인########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959724c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6e846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b5d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb213e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9da0d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|_c0|                text|label|               pos_t|               neg_t|     filtered_words1|     filtered_words2|         rawFeatures|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|threatmeter hacke...|    0|[threatmeter, hac...|[threatmeter, hac...|[threatmeter, hac...|[threatmeter, hac...|(100,[7,12,15,20,...|\n",
      "|  1|first android mal...|    0|[first, android, ...|[first, android, ...|[first, android, ...|[first, android, ...|(100,[3,11,40,69,...|\n",
      "|  2|adobe fixes six c...|    0|[adobe, fixes, si...|[adobe, fixes, si...|[adobe, fixes, si...|[adobe, fixes, si...|(100,[5,20,40,45,...|\n",
      "|  3| scienceporn  in ...|    0|[scienceporn, in,...|[scienceporn, in,...|[scienceporn, vac...|[scienceporn, vac...|(100,[29,38,45,70...|\n",
      "|  4|riskware hmoyfzb ...|    0|[riskware, hmoyfz...|[riskware, hmoyfz...|[riskware, hmoyfz...|[riskware, hmoyfz...|(100,[68,71],[2.0...|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "hashingTF = HashingTF(inputCol=\"pos_t\", outputCol=\"rawFeatures\", numFeatures=100)\n",
    "featurizedData = hashingTF.transform(r4)\n",
    "featurizedData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8131b841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)    169\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)    144\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)    118\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)    115\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0)    110\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ... \n",
       "(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)      1\n",
       "(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)      1\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)      1\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0)      1\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)      1\n",
       "Name: rawFeatures, Length: 175913, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizedData = featurizedData.toPandas()\n",
    "featurizedData['rawFeatures'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c0e6f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featurizedData['rawFeatures'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### rawFeatures input으로 사용해서 모델 돌려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cc6369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "stage_3_a = CountVectorizer(inputCol=stage_2_a.getOutputCol(), outputCol='word1', vocabSize=50, minDF=2.0)\n",
    "stage_3_b = CountVectorizer(inputCol=stage_2_b.getOutputCol(), outputCol='word2', vocabSize=50, minDF=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "160fa55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages= [stage_1_a, stage_1_b, stage_2_a, stage_2_b, stage_3_a, stage_3_b])\n",
    "pipelineFit = pipeline.fit(csi_pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "831d9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform = pipelineFit.transform(csi_pos_neg)\n",
    "dfdfdf = df_transform.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c71536df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfdfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "585753e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)    84912\n",
       "(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)     5534\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)     3799\n",
       "(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)     3758\n",
       "(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)     3700\n",
       "                                                                                                                                                                                                                                                              ...  \n",
       "(2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)        1\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)        1\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)        1\n",
       "(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)        1\n",
       "(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)        1\n",
       "Name: word1, Length: 6925, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdfdf['word1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08e6afcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfdfdf['word1'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10251aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "stage_3_a = CountVectorizer(inputCol=stage_2_a.getOutputCol(), outputCol='word1', vocabSize=100, minDF=2.0)\n",
    "stage_3_b = CountVectorizer(inputCol=stage_2_b.getOutputCol(), outputCol='word2', vocabSize=100, minDF=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f21f8e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+---------------+\n",
      "|_c0|                text|label|               pos_t|               neg_t|     filtered_words1|     filtered_words2|          word1|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+---------------+\n",
      "|  0|threatmeter hacke...|    0|[threatmeter, hac...|[threatmeter, hac...|[threatmeter, hac...|[threatmeter, hac...| (50,[4],[1.0])|\n",
      "|  1|first android mal...|    0|[first, android, ...|[first, android, ...|[first, android, ...|[first, android, ...|(50,[29],[1.0])|\n",
      "|  2|adobe fixes six c...|    0|[adobe, fixes, si...|[adobe, fixes, si...|[adobe, fixes, si...|[adobe, fixes, si...|     (50,[],[])|\n",
      "|  3| scienceporn  in ...|    0|[scienceporn, in,...|[scienceporn, in,...|[scienceporn, vac...|[scienceporn, vac...|     (50,[],[])|\n",
      "|  4|riskware hmoyfzb ...|    0|[riskware, hmoyfz...|[riskware, hmoyfz...|[riskware, hmoyfz...|[riskware, hmoyfz...|     (50,[],[])|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = stage_3_a.fit(r4)\n",
    "r5 = model.transform(r4)\n",
    "r5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96bacea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+---------------+---------------+\n",
      "|_c0|                text|label|               pos_t|               neg_t|     filtered_words1|     filtered_words2|          word1|          word2|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+---------------+---------------+\n",
      "|  0|threatmeter hacke...|    0|[threatmeter, hac...|[threatmeter, hac...|[threatmeter, hac...|[threatmeter, hac...| (50,[4],[1.0])| (50,[4],[1.0])|\n",
      "|  1|first android mal...|    0|[first, android, ...|[first, android, ...|[first, android, ...|[first, android, ...|(50,[29],[1.0])|(50,[29],[1.0])|\n",
      "|  2|adobe fixes six c...|    0|[adobe, fixes, si...|[adobe, fixes, si...|[adobe, fixes, si...|[adobe, fixes, si...|     (50,[],[])|     (50,[],[])|\n",
      "|  3| scienceporn  in ...|    0|[scienceporn, in,...|[scienceporn, in,...|[scienceporn, vac...|[scienceporn, vac...|     (50,[],[])|     (50,[],[])|\n",
      "|  4|riskware hmoyfzb ...|    0|[riskware, hmoyfz...|[riskware, hmoyfz...|[riskware, hmoyfz...|[riskware, hmoyfz...|     (50,[],[])|     (50,[],[])|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = stage_3_b.fit(r5)\n",
    "r6 = model2.transform(r5)\n",
    "r6.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b82fd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols= [stage_3_a.getOutputCol(), stage_3_b.getOutputCol()], outputCol= 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dd3fd34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+---------------+---------------+-----------------------+\n",
      "|_c0|text                                                                                                                |label|pos_t                                                                                                                                |neg_t                                                                                                                                |filtered_words1                                                                                                      |filtered_words2                                                                                                      |word1          |word2          |features               |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+---------------+---------------+-----------------------+\n",
      "|0  |threatmeter hacked emails of san francisco muni rail system hacker reveals clues about identity and tactics kr  fin |0    |[threatmeter, hacked, emails, of, san, francisco, muni, rail, system, hacker, reveals, clues, about, identity, and, tactics, kr, fin]|[threatmeter, hacked, emails, of, san, francisco, muni, rail, system, hacker, reveals, clues, about, identity, and, tactics, kr, fin]|[threatmeter, hacked, emails, san, francisco, muni, rail, system, hacker, reveals, clues, identity, tactics, kr, fin]|[threatmeter, hacked, emails, san, francisco, muni, rail, system, hacker, reveals, clues, identity, tactics, kr, fin]|(50,[4],[1.0]) |(50,[4],[1.0]) |(100,[4,54],[1.0,1.0]) |\n",
      "|1  |first android malware targeting pcs uncovered  fbxtynm                                                              |0    |[first, android, malware, targeting, pcs, uncovered, fbxtynm]                                                                        |[first, android, malware, targeting, pcs, uncovered, fbxtynm]                                                                        |[first, android, malware, targeting, pcs, uncovered, fbxtynm]                                                        |[first, android, malware, targeting, pcs, uncovered, fbxtynm]                                                        |(50,[29],[1.0])|(50,[29],[1.0])|(100,[29,79],[1.0,1.0])|\n",
      "|2  |adobe fixes six code execution bugs in flash  mokgxr                                                                |0    |[adobe, fixes, six, code, execution, bugs, in, flash, mokgxr]                                                                        |[adobe, fixes, six, code, execution, bugs, in, flash, mokgxr]                                                                        |[adobe, fixes, six, code, execution, bugs, flash, mokgxr]                                                            |[adobe, fixes, six, code, execution, bugs, flash, mokgxr]                                                            |(50,[],[])     |(50,[],[])     |(100,[],[])            |\n",
      "|3  | scienceporn  in a vacuum i guess                                                                                   |0    |[scienceporn, in, a, vacuum, i, guess]                                                                                               |[scienceporn, in, a, vacuum, i, guess]                                                                                               |[scienceporn, vacuum, guess]                                                                                         |[scienceporn, vacuum, guess]                                                                                         |(50,[],[])     |(50,[],[])     |(100,[],[])            |\n",
      "|4  |riskware hmoyfzb  fbjaz                                                                                             |0    |[riskware, hmoyfzb, fbjaz]                                                                                                           |[riskware, hmoyfzb, fbjaz]                                                                                                           |[riskware, hmoyfzb, fbjaz]                                                                                           |[riskware, hmoyfzb, fbjaz]                                                                                           |(50,[],[])     |(50,[],[])     |(100,[],[])            |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------+---------------+---------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r7 = vectorAssembler.transform(r6)\n",
    "r7.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5559a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f26880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a16762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7c731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d253f64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------------------------+\n",
      "|features  |polyFeatures                              |\n",
      "+----------+------------------------------------------+\n",
      "|[2.0,1.0] |[2.0,4.0,8.0,1.0,2.0,4.0,1.0,2.0,1.0]     |\n",
      "|[0.0,0.0] |[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]     |\n",
      "|[3.0,-1.0]|[3.0,9.0,27.0,-1.0,-3.0,-9.0,1.0,3.0,-1.0]|\n",
      "+----------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (Vectors.dense([2.0, 1.0]),),\n",
    "    (Vectors.dense([0.0, 0.0]),),\n",
    "    (Vectors.dense([3.0, -1.0]),)\n",
    "], [\"features\"])\n",
    "\n",
    "polyExpansion = PolynomialExpansion(degree=3, inputCol=\"features\", outputCol=\"polyFeatures\")\n",
    "polyDF = polyExpansion.transform(df)\n",
    "\n",
    "polyDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82305afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------+\n",
      "| id|category|categoryIndex|\n",
      "+---+--------+-------------+\n",
      "|  0|       a|          0.0|\n",
      "|  1|       b|          2.0|\n",
      "|  2|       c|          1.0|\n",
      "|  3|       a|          0.0|\n",
      "|  4|       a|          0.0|\n",
      "|  5|       c|          1.0|\n",
      "+---+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [(0, \"a\"), (1, \"b\"), (2, \"c\"), (3, \"a\"), (4, \"a\"), (5, \"c\")],\n",
    "    [\"id\", \"category\"])\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\n",
    "indexed = indexer.fit(df).transform(df)\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade28342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f16f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7613ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03908ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e7a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4229822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed9e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e23425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages= [stage_1_a, stage_1_b, stage_2_a, stage_2_b, stage_3_a, stage_3_b, vectorAssembler])\n",
    "pipelineFit = pipeline.fit(csi_pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b12d4b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pos_t</th>\n",
       "      <th>neg_t</th>\n",
       "      <th>filtered_words1</th>\n",
       "      <th>filtered_words2</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>threatmeter hacked emails of san francisco mun...</td>\n",
       "      <td>0</td>\n",
       "      <td>[threatmeter, hacked, emails, of, san, francis...</td>\n",
       "      <td>[threatmeter, hacked, emails, of, san, francis...</td>\n",
       "      <td>[threatmeter, hacked, emails, san, francisco, ...</td>\n",
       "      <td>[threatmeter, hacked, emails, san, francisco, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>first android malware targeting pcs uncovered ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[first, android, malware, targeting, pcs, unco...</td>\n",
       "      <td>[first, android, malware, targeting, pcs, unco...</td>\n",
       "      <td>[first, android, malware, targeting, pcs, unco...</td>\n",
       "      <td>[first, android, malware, targeting, pcs, unco...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>adobe fixes six code execution bugs in flash  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[adobe, fixes, six, code, execution, bugs, in,...</td>\n",
       "      <td>[adobe, fixes, six, code, execution, bugs, in,...</td>\n",
       "      <td>[adobe, fixes, six, code, execution, bugs, fla...</td>\n",
       "      <td>[adobe, fixes, six, code, execution, bugs, fla...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>scienceporn  in a vacuum i guess</td>\n",
       "      <td>0</td>\n",
       "      <td>[scienceporn, in, a, vacuum, i, guess]</td>\n",
       "      <td>[scienceporn, in, a, vacuum, i, guess]</td>\n",
       "      <td>[scienceporn, vacuum, guess]</td>\n",
       "      <td>[scienceporn, vacuum, guess]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>riskware hmoyfzb  fbjaz</td>\n",
       "      <td>0</td>\n",
       "      <td>[riskware, hmoyfzb, fbjaz]</td>\n",
       "      <td>[riskware, hmoyfzb, fbjaz]</td>\n",
       "      <td>[riskware, hmoyfzb, fbjaz]</td>\n",
       "      <td>[riskware, hmoyfzb, fbjaz]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                               text label  \\\n",
       "0   0  threatmeter hacked emails of san francisco mun...     0   \n",
       "1   1  first android malware targeting pcs uncovered ...     0   \n",
       "2   2  adobe fixes six code execution bugs in flash  ...     0   \n",
       "3   3                   scienceporn  in a vacuum i guess     0   \n",
       "4   4                           riskware hmoyfzb  fbjaz      0   \n",
       "\n",
       "                                               pos_t  \\\n",
       "0  [threatmeter, hacked, emails, of, san, francis...   \n",
       "1  [first, android, malware, targeting, pcs, unco...   \n",
       "2  [adobe, fixes, six, code, execution, bugs, in,...   \n",
       "3             [scienceporn, in, a, vacuum, i, guess]   \n",
       "4                         [riskware, hmoyfzb, fbjaz]   \n",
       "\n",
       "                                               neg_t  \\\n",
       "0  [threatmeter, hacked, emails, of, san, francis...   \n",
       "1  [first, android, malware, targeting, pcs, unco...   \n",
       "2  [adobe, fixes, six, code, execution, bugs, in,...   \n",
       "3             [scienceporn, in, a, vacuum, i, guess]   \n",
       "4                         [riskware, hmoyfzb, fbjaz]   \n",
       "\n",
       "                                     filtered_words1  \\\n",
       "0  [threatmeter, hacked, emails, san, francisco, ...   \n",
       "1  [first, android, malware, targeting, pcs, unco...   \n",
       "2  [adobe, fixes, six, code, execution, bugs, fla...   \n",
       "3                       [scienceporn, vacuum, guess]   \n",
       "4                         [riskware, hmoyfzb, fbjaz]   \n",
       "\n",
       "                                     filtered_words2  \\\n",
       "0  [threatmeter, hacked, emails, san, francisco, ...   \n",
       "1  [first, android, malware, targeting, pcs, unco...   \n",
       "2  [adobe, fixes, six, code, execution, bugs, fla...   \n",
       "3                       [scienceporn, vacuum, guess]   \n",
       "4                         [riskware, hmoyfzb, fbjaz]   \n",
       "\n",
       "                                               word1  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                               word2  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transform = pipelineFit.transform(csi_pos_neg)\n",
    "df_transform.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "227cfb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform_fin = df_transform.orderBy(rand())\n",
    "nb_classes = df_transform_fin.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "624eae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = 5001\n",
    "neg_vocab_sizes = 5001\n",
    "embedding_vector_length = 100\n",
    "hidden_dims = 250\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1c41523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from tensorflow.python.keras.layers import Conv1D, Flatten, GlobalMaxPooling1D, Dropout, MaxPooling1D, Activation, Bidirectional, Conv2D, GlobalMaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af49ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSI positive Embedding model\n",
    "inputA = Input(shape=(100,))\n",
    "x = Embedding(vocab_sizes, embedding_vector_length, input_length=max_length)(inputA)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x = MaxPool1D(strides=1, padding='valid')(x)\n",
    "x = Bidirectional(LSTM(128))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# CSI negative Embedding model\n",
    "inputC = Input(shape=(100,))\n",
    "k = Embedding(neg_vocab_sizes, embedding_vector_length, input_length=max_length)(inputC)\n",
    "# k = Conv1D(128, 5, activation='relu')(k)\n",
    "# k = MaxPool1D(strides=1, padding='valid')(k)\n",
    "k = Bidirectional(LSTM(128))(k)\n",
    "k = Dropout(0.2)(k)\n",
    "k = Activation('relu')(k)\n",
    "k = Model(inputs=inputC, outputs=k)\n",
    "\n",
    "combined = concatenate([x.output, k.output], axis=1)\n",
    "# z = Flatten()(combined)\n",
    "z = Dense(8, activation='relu')(combined)\n",
    "z = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, k.input], outputs=z)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ef73fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 100)     500100      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 100)     500100      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 256)          234496      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 256)          234496      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            4104        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            9           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,473,305\n",
      "Trainable params: 1,473,305\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c98031ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer_conf = optimizers.Adam(lr=0.01)\n",
    "opt_conf = optimizers.serialize(optimizer_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6f4a9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElephasEstimator_907d50e28eff"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from elephas import spark_model, ml_model\n",
    "from elephas.ml_model import ElephasEstimator\n",
    "\n",
    "estimator = ElephasEstimator()\n",
    "estimator.setFeaturesCol(\"features\")\n",
    "estimator.setLabelCol(\"label\")\n",
    "estimator.set_keras_model_config(model.to_json())\n",
    "# estimator.set_categorical_labels(True)\n",
    "estimator.set_nb_classes(nb_classes)\n",
    "estimator.set_num_workers(2)\n",
    "estimator.set_epochs(3)\n",
    "estimator.set_batch_size(32)\n",
    "estimator.set_verbosity(1)\n",
    "estimator.set_validation_split(0.10)\n",
    "estimator.set_optimizer_config(opt_conf)\n",
    "estimator.set_mode(\"synchronous\")\n",
    "estimator.set_loss(\"binary_crossentropy\")\n",
    "# estimator.set_metrics(['acc'])\n",
    "\n",
    "dl_pipeline = Pipeline(stages=[estimator])\n",
    "my_dl = dl_pipeline.fit(df_transform_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "519b39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_pipeline = Pipeline(stages=[estimator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d31e20fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Fit model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-60558f6b0a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_transform_fin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/spark/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/elephas/ml_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                         validation_split=self.get_validation_split())\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mmodel_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, rdd, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'asynchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'synchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hogwild'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, rdd, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             worker = SparkWorker(yaml, parameters, train_config,\n\u001b[1;32m    184\u001b[0m                                  optimizer, loss, metrics, custom)\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mtraining_outcomes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0mnew_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mnumber_of_sub_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_outcomes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \"\"\"\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_dl = dl_pipeline.fit(df_transform_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48581fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dl.write().overwrite().save('hdfs:///user/root/model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd6043d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
